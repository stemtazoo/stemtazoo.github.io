---
layout: page
title: 不純度とは？決定木での「混ざり具合」の意味【DS検定】
permalink: /ds/impurity/
tags: [ds, ai, evaluation]
---

## まず結論
不純度とは、**データがどれだけ混ざっているか（クラスがどれだけバラバラか）を表す指標**です。  
DS検定では、「良い分岐とは何か？」を判断させる問題で問われます。

---

## 直感的な説明

たとえば、あるグループに

- すべて「合格」
- すべて「不合格」

のどちらかだけが入っていれば、とても分かりやすい状態です。

→ これは「純粋（不純度が低い）」です。

一方で、

- 合格と不合格が半々に混ざっている

→ これは「混ざっている（不純度が高い）」状態です。

つまり、

> 不純度が低い = クラスがはっきりしている  
> 不純度が高い = クラスが混ざっている

これが本質です。

---

## 定義・仕組み

不純度とは、

> あるノード（分岐後のグループ）のクラスの混ざり具合

を数値化したものです。

代表的な指標は2つあります。

### ① ジニ不純度（Gini impurity）
- ランダムフォレストでよく使われる
- 計算が軽い

### ② エントロピー（Entropy）
- 情報利得で使われる
- 情報理論ベース

どちらも考え方は同じです。

> クラスが均等に混ざるほど値は大きくなる  
> 1種類だけになると最小になる

DS検定では、数式よりも

「混ざり具合を測る指標」

と理解していれば十分です。

---

## どんな場面で使う？

### ① 決定木の分岐基準

決定木は、

「どの特徴量で分けると一番きれいに分かれるか？」

を判断します。

このとき、

> 分岐後の不純度が小さくなるように特徴量を選ぶ

というルールを使います。

つまり、

- 不純度が大きく下がる分岐 = 良い分岐

です。

---

### ② ランダムフォレストの内部

ランダムフォレストも、各決定木で  
不純度を下げる方向に分岐します。

その「どれだけ下げたか」の合計が  
特徴量重要度に使われることがあります。

---

## よくある誤解・混同

### ❌ 不純度が大きいほど良い
→ 逆です。

**小さいほど良い状態**です。

DS検定では  
「不純度が最大のときが最良」といった選択肢が出たら誤りです。

---

### ❌ 不純度 = 情報利得
→ 違います。

- 不純度 → 今の混ざり具合
- 情報利得 → 分岐でどれだけ不純度が減ったか

この違いはよく問われます。

---

### ❌ 不純度が低い = モデルが高精度
→ 必ずしもそうではありません。

1つのノードが純粋でも、  
全体として汎化できるとは限りません。

ここは「過学習」と絡めて出題されることがあります。

---

## まとめ（試験直前用）

- 不純度 = クラスの混ざり具合
- 小さいほど良い状態
- 決定木は不純度を下げる方向に分岐する
- 情報利得は「不純度の減少量」
- 不純度と精度は同義ではない

---

## 対応スキル項目（AI利活用スキルシート）
- AIの理解
- 機械学習の基本理解
- ★ 機械学習モデルの基本的な仕組みを理解している
