---
layout: page
title: バイアス・バリアンスのトレードオフとは？過学習との関係【DS検定】
permalink: /ds/bias-variance-tradeoff/
tags: [ds, ai, evaluation]
---

## まず結論
バイアス・バリアンスのトレードオフとは、**モデルを複雑にするとバイアスは下がるがバリアンスが上がる、という関係**のことです。  
DS検定では、「過学習と未学習（アンダーフィット）の違い」を説明できるかが問われます。

---

## 直感的な説明

モデルを「ルールの細かさ」と考えてみましょう。

### ルールがざっくり（単純すぎる）
- データの傾向をうまく表せない
- どのデータでも同じような予測をする
→ これは **バイアスが大きい状態**

---

### ルールが細かすぎる
- 学習データには完璧に合う
- 新しいデータではブレやすい
→ これは **バリアンスが大きい状態**

つまり、

> 単純すぎてもダメ  
> 複雑すぎてもダメ  

このバランスを取る必要があります。

---

## 定義・仕組み

### バイアス（Bias）

> モデルの「思い込みの強さ」

単純なモデルほど、
本来の関係をうまく表せません。

→ アンダーフィットにつながる

---

### バリアンス（Variance）

> データの変化に対する「敏感さ」

複雑なモデルほど、
データのわずかな違いに影響されやすくなります。

→ 過学習につながる

---

### トレードオフとは？

モデルを複雑にすると：

- バイアス ↓
- バリアンス ↑

モデルを単純にすると：

- バイアス ↑
- バリアンス ↓

この逆方向の関係が「トレードオフ」です。

---

## どんな場面で使う？

### ① 決定木の深さ調整

- 浅い木 → 高バイアス
- 深い木 → 高バリアンス

前回の「過学習と分岐の深さ」の話は、  
まさにこの理論です。

---

### ② 正則化の理解

- 正則化を強くする → モデルを単純化 → バイアス増、バリアンス減
- 正則化を弱くする → 複雑化 → バイアス減、バリアンス増

DS検定ではここが狙われます。

---

## よくある誤解・混同

### ❌ バイアスが小さいほど良い
→ 小さすぎるとバリアンスが大きくなる可能性があります。

---

### ❌ バリアンスは分散のこと
→ 数学的な分散とは違い、
「予測のブレやすさ」という意味です。

---

### ❌ トレードオフは決定木だけの話
→ すべての機械学習モデルに共通する概念です。

---

### ❌ 過学習 = バイアスが大きい
→ 過学習は **バリアンスが大きい状態** です。

ここはよく出題されます。

---

## まとめ（試験直前用）

- バイアス = モデルの単純さによる誤差
- バリアンス = データ変動への敏感さ
- 単純すぎる → 高バイアス（未学習）
- 複雑すぎる → 高バリアンス（過学習）
- 両者は逆方向に動く（トレードオフ）

---

## 対応スキル項目（AI利活用スキルシート）
- AIの理解
- 機械学習の基本理解
- ★ 機械学習モデルの基本的な仕組みを理解している
