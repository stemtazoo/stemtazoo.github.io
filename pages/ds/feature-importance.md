---
layout: page
title: 特徴量重要度とは？不純度ベースとPermutationの違い【DS検定】
permalink: /ds/feature-importance/
tags: [ds, ai, evaluation]
---

## まず結論
特徴量重要度とは、**どの特徴量が予測にどれだけ貢献しているかを示す指標**です。  
DS検定では、「重要度の算出方法の違い」を理解し、選択肢を正しく切れるかが問われます。

---

## 直感的な説明

たとえば、売上予測モデルがあるとします。

- 「価格」は予測にかなり効いている
- 「曜日」は少し効いている
- 「商品ID」はほぼ関係ない

この「どれがどれくらい効いているか」を数値にしたものが特徴量重要度です。

ただし、

> 重要度の出し方には2種類ある

ここがDS検定のポイントです。

---

## 定義・仕組み

代表的な方法は次の2つです。

---

### ① 不純度ベース重要度（Gini importance）

考え方：
> 分岐によってどれだけ不純度を下げたかの合計

ランダムフォレストでは、
各決定木の分岐で使われた特徴量が、
どれだけ不純度を減らしたかを合計します。

特徴：

- 計算が速い
- モデル内部で算出される
- sklearnの `feature_importances_` がこれ

---

### ② Permutation Importance（置換重要度）

考え方：
> その特徴量をシャッフルして、精度がどれだけ下がるかを見る

手順：

1. 学習済みモデルを用意
2. ある特徴量だけをランダムに並び替える
3. 精度の落ち幅を測る

特徴：

- 予測への影響を直接評価できる
- 計算コストが高い
- 相関が強い特徴量があると重要度が分散する

---

## どんな場面で使う？

### 不純度ベース

- ランダムフォレストの内部理解
- ざっくり重要度を見るとき
- 実務の初期分析

---

### Permutation Importance

- 本当に予測に効いているかを確認したいとき
- モデルの説明性を高めたいとき
- ビジネス説明資料を作るとき

DS検定では、

> 「どの方法が予測への影響を直接測るか？」

という聞き方がよく出ます。

答えは **Permutation Importance** です。

---

## よくある誤解・混同

### ❌ 重要度が高い = 因果関係がある
→ 誤りです。

予測に役立つだけで、原因とは限りません。

---

### ❌ 不純度ベース重要度は常に正確
→ 偏りが出ることがあります。

カテゴリ数が多い特徴量が有利になることがあります。

---

### ❌ Permutation Importanceは相関の影響を受けない
→ 受けます。

強い相関があると、片方を壊してももう片方が代替するため、
重要度が低く見えることがあります。

---

### ❌ 重要度が低い = その特徴量は不要
→ 必ずしもそうではありません。

相互作用や複雑な構造がある場合は、
単独では重要でなくても意味を持つことがあります。

---

## まとめ（試験直前用）

- 特徴量重要度 = 予測への貢献度
- 不純度ベース → 分岐でどれだけ不純度を下げたか
- Permutation → シャッフルして精度の落ち幅を見る
- 因果を示す指標ではない
- 「直接予測への影響を測る」のはPermutation

---

## 対応スキル項目（AI利活用スキルシート）
- AIの理解
- 機械学習の基本理解
- ★ 機械学習モデルの基本的な仕組みを理解している
