---
layout: page
title: CBOW と Skip-gram の違いとは？G検定対策
permalink: /gk/cbow-vs-skipgram/
tags: [gk, nlp]
gk_section: ディープラーニングの応用例/自然言語処理
gk_order: 16
---

## まず結論

* **CBOW（Continuous Bag of Words）**と**Skip-gram**は、Word2Vecで使われる単語埋め込み（Embedding）の学習方法です。
* G検定では「**どちらが入力で、どちらを予測するか**」「**低頻度語に強いのはどちらか**」がよく問われます。

## 直感的な説明

* **CBOW** は「**まわりの単語から、真ん中の単語を当てる**」方式です。

  * 前後の文脈 → 中心語
* **Skip-gram** は「**真ん中の単語から、まわりの単語を当てる**」方式です。

  * 中心語 → 周囲の文脈
* 問題文で「**どちらを予測しているか**」を見ると、一気に判別できます。

## 定義・仕組み

* **CBOW**

  * 入力：周囲の単語（文脈）
  * 出力：中心の単語
  * 複数の単語情報を平均的に使う

* **Skip-gram**

  * 入力：中心の単語
  * 出力：周囲の単語
  * 1単語から複数の文脈を予測

* どちらも学習結果として **Embedding（分散表現）** を得る点は共通です。

## いつ使う？（得意・不得意）

### CBOW

* 得意：

  * 学習が速い
  * 大規模データで安定
* 不得意：

  * 低頻度語の表現が弱くなりやすい

### Skip-gram

* 得意：

  * 低頻度語の学習に強い
  * 精度が高くなりやすい
* 不得意：

  * 計算コストが高い

## G検定ひっかけポイント

* **CBOW と Skip-gram はどちらも学習手法**

  * モデルや表現形式ではない
* 選択肢で

  * 「周囲の単語から中心語を予測」→ CBOW
  * 「中心語から周囲の単語を予測」→ Skip-gram
* 「低頻度語に強い」→ Skip-gram
* **入力と出力の向きが逆**、これが最大の判断基準

## まとめ（試験直前用）

* CBOW：文脈 → 中心語、速い
* Skip-gram：中心語 → 文脈、低頻度語に強い
* どちらも Word2Vec の学習方法
* 予測方向を見れば切れる
