---
layout: page
title: バイアスとバリアンスとは？（トレードオフ）【G検定対策】
permalink: /gk/bias-variance/
tags: [gk, metrics]
gk_section: 機械学習の概要/モデルの選択・評価
gk_order: 18
---

## まず結論

バイアスとバリアンスは**トレードオフの関係**にあり、G検定では「バイアスが大きいとアンダーフィッティング」「バリアンスが大きいとオーバーフィッティング」と正しく対応づけられるかが問われる。

## 直感的な説明

まずイメージで整理します。

* **バイアス（Bias）**：

  * モデルの考え方のクセ
  * そもそもズレた見方をしている状態

* **バリアンス（Variance）**：

  * データへの敏感さ
  * データが少し変わるだけで結果がブレる状態

たとえるなら、

* バイアスが大きい → 雑なルールで決めつける
* バリアンスが大きい → 細かく気にしすぎる

## 定義・仕組み

### バイアス（Bias）

* モデルが単純すぎることで生じる誤差
* 表現力不足が原因

### バリアンス（Variance）

* モデルが複雑すぎることで生じる誤差
* データへの過度な適合が原因

両者は同時に小さくしにくく、
**一方を下げるともう一方が上がりやすい**関係にあります。

## いつ使う？（得意・不得意）

### バイアスが大きい状態

* アンダーフィッティング（学習不足）
* 学習データもテストデータも精度が低い

### バリアンスが大きい状態

* オーバーフィッティング（過学習）
* 学習データは高精度、テストデータは低精度

## G検定ひっかけポイント

G検定では、**用語の入れ替え**を狙ってきます。

### よくあるひっかけ

* バイアス ↔ バリアンスを逆にする
* ノイズを混ぜる

### 正誤を切る判断基準

* **学習不足？** → バイアスが大きい
* **過学習？** → バリアンスが大きい

選択肢で

> 「Aが大きいとアンダーフィッティング」

とあれば、A＝バイアスです。

## まとめ（試験直前用）

* バイアスとバリアンスはトレードオフ
* バイアス大 → アンダーフィッティング
* バリアンス大 → オーバーフィッティング
* ノイズは別概念
* G検定では対応関係を即断
