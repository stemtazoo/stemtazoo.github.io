---
layout: page
title: 交差検証（Cross Validation）とは？【k分割の考え方｜G検定対策】
permalink: /gk/cross-validation/
tags: [gk, machine_learning, evaluation]
gk_section: 機械学習の概要/モデルの選択・評価
gk_order: 13
---

## まず結論
- **交差検証（Cross Validation）**とは、データを複数に分割して、学習と検証を入れ替えながら性能を評価する手法である。
- G検定では「**検証データの使い方**」と「**テストデータとの違い**」が問われる。

## 直感的な説明
交差検証は、  
**模試を何パターンも受けて、平均点で実力を判断する方法**です。

- 1回の模試だけだと運に左右される  
- 何回も受ければ、実力が分かる  

👉 **評価のブレを小さくする**のが目的。

## 定義・仕組み
### k分割交差検証（k-fold Cross Validation）
1. データを k 個に分割
2. そのうち 1つを検証用にする
3. 残りを学習用にする
4. これを k 回繰り返す
5. 検証結果を平均する

👉 **すべてのデータが一度は検証に使われる**

## いつ使う？（得意・不得意）
### 得意なケース
- データ数が少ない
- 評価の信頼性を高めたい
- モデル比較をしたい

### 不得意・注意点
- 計算コストが高い
- 大規模データでは非効率
- 時系列データにはそのまま使えない

## G検定ひっかけポイント
ここが超重要 👇

### ❌ テストデータで交差検証を行う
- **誤り**
- 交差検証は「学習＋検証」の枠内で行う

### ❌ 検証データを何度も使うのはデータリーケージ
- **誤り**
- 交差検証では「意図的に」入れ替えて使うため問題なし

### ⭕ 正しい理解
- 交差検証＝検証の安定化
- テストデータ＝最後の1回だけ使用

### 学習・検証・テストの関係
- 学習：重み更新
- 検証：評価（交差検証を含む）
- テスト：最終評価のみ

## まとめ（試験直前用）
- 交差検証＝評価を安定させる手法
- k分割が代表例
- 検証データを入れ替えて使う
- テストデータは使わない
- 時系列では注意
