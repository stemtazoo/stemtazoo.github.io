---
layout: page
title: FCN（Fully Convolutional Network）
permalink: /gk/fcn/
tags: [gk, neural_network, cnn]
---

## まず結論

**FCN（Fully Convolutional Network）は、画像分類用の CNN を「全結合層なし（畳み込みだけ）」に作り替えて、
画素ごとの分類（セマンティックセグメンテーション）を可能にした基本モデルです。**

U-Net や SegNet のような後継モデルが出てくる前の、
**セグメンテーション CNN の“出発点”**として押さえるのが G検定では重要です。

---

## 直感的な説明

普通の画像分類 CNN は、最後に

* 特徴をまとめる（小さくする）
* 最後に **全結合層（FC層）**で 1 枚のラベルを出す

という流れです。

でもセマンティックセグメンテーションは、

👉 **1枚のラベルじゃなくて、画素ごとにラベルが欲しい**

ので、最後の「全結合層」が邪魔になります。

FCN はここを発想転換して、

* 全結合層をやめる（＝全部を畳み込みにする）
* 低解像度になった特徴マップを **アップサンプリング**して元サイズに戻す

ことで、画素単位の出力を実現します。

---

## 定義・仕組み

### FCN とは

* **Fully Convolutional（全て畳み込み）**
* 全結合層を使わず、畳み込み層だけで構成する
* 出力を **画像（マップ）として返す**ことで画素単位の分類ができる

### どうやって元の解像度に戻す？

分類 CNN は途中でプーリングなどにより解像度が下がります。
FCN はそこから

* **アップサンプリング**
  -（実装上は転置畳み込み/デコンボリューション等）

で元のサイズへ戻します。

### 追加の重要ポイント：スキップ接続（skip connection）

FCN はアップサンプリングだけだと粗くなりやすいので、
途中の層の情報（より細かい解像度）を足し合わせる **スキップ接続** を使うことがあります。

ここが U-Net の「特徴マップを結合する」発想にもつながります。

---

## いつ使う？（得意・不得意）

### 得意なこと

* セマンティックセグメンテーションの基本形として理解しやすい
* 既存の分類 CNN（VGG など）をベースに拡張しやすい

### 不得意なこと

* 境界がぼやけやすい（低解像度→アップサンプリングの限界）
* U-Net や SegNet のような「境界を強く保つ工夫」が弱め

---

## G検定ひっかけポイント

### ① 「FCN」＝ 全結合層（Fully Connected）と勘違い

ここが最頻出の罠です。

* ❌ FCN = Fully Connected Network（全結合のネットワーク）
* ⭕ FCN = **Fully Convolutional Network（全て畳み込み）**

👉 「FCN」という略語が、逆の意味に見えるのが罠。
G検定はここを狙ってきます。

---

### ② 画像分類モデルとの違い

* 画像分類：画像全体に 1 ラベル
* FCN：画像（マップ）として出力 → 画素ごとにラベル

👉 「画素ごとの分類」「セマンティックセグメンテーション」
と書いてあれば FCN 系を疑う

---

### ③ U-Net / SegNet との関係

* **FCN**：セグメンテーション CNN の基本（出発点）
* **U-Net**：特徴マップをスキップ接続で“結合”して精度改善
* **SegNet**：最大値プーリングの“位置”を記憶して境界を保つ

👉 同じ Encoder-Decoder っぽく見えても、
**「何を渡すか」**が違う

---

## まとめ（試験直前用）

* FCN は **Fully Convolutional Network**（全結合層なし）
* 画像分類 CNN を拡張して **画素ごとの分類**を可能にした基本モデル
* 解像度を下げた特徴マップを **アップサンプリング**して元に戻す
* 罠：FCN を Fully Connected と勘違いしない

👉 **「FCN = 全部畳み込み」**
