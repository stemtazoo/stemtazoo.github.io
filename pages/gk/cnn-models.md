---
layout: page
title: CNN代表モデルまとめ（LeNet / AlexNet / VGG / ResNet）
permalink: /gk/cnn-models/
tags: [gk, neural_network, cnn, models]
---

## まず結論

* **CNNは課題に応じて進化してきた**
* 各モデルは「何を解決したか」で覚える
* G検定では **モデル名と特徴の対応** が頻出

---

## 直感的な説明

CNNの代表モデルは、

> 「前のモデルの弱点をどう克服したか」

という視点で並んでいます。

* 精度を上げたい
* 深くしたい
* 勾配が消えるのを防ぎたい

という課題に対する **回答の歴史** です。

---

## 代表的なCNNモデル

### LeNet（1998）

**位置づけ**

* CNNの原点

**特徴**

* 畳み込み + プーリング + 全結合
* 手書き数字認識（MNIST）

---

### AlexNet（2012）

**位置づけ**

* 深層学習ブームの火付け役

**特徴**

* ReLUの採用
* GPUによる高速学習
* Dropoutで過学習対策

---

### VGG（2014）

**位置づけ**

* シンプル構造で高性能

**特徴**

* **小さなフィルタ（3×3）を多数積む**
* 構造が分かりやすい

---

### ResNet（2015）

**位置づけ**

* 超深層化を可能にしたモデル

**特徴**

* **スキップ接続（残差接続）**
* 勾配消失問題を緩和

---

## いつ使う？（得意・不得意）

| モデル     | 覚えるポイント          |
| ------- | ---------------- |
| LeNet   | CNNの原点           |
| AlexNet | ReLU・GPU・Dropout |
| VGG     | 小さなフィルタを深く       |
| ResNet  | スキップ接続で深層化       |

---

## G検定ひっかけポイント

* ❌「VGGはスキップ接続を使う」→ **誤り**
* ❌「ResNetは浅いネットワーク」→ **誤り**
* ✅ AlexNet＝ReLU・GPU
* ✅ ResNet＝勾配消失対策

---

## まとめ（試験直前用）

* CNNモデルは **進化の流れで覚える**
* モデル名と特徴を1対1で対応づける
* ResNetは深層化の決定打

👉 次は **RNN（再帰型ニューラルネットワーク）** に進めます。
