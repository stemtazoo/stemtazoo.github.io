---
layout: page
title: β-VAE・infoVAE・VQ-VAEの違い【G検定頻出比較】
permalink: /gk/vae-variants-cheatsheet/
tags: [gk, generative_model, neural_network, cheatsheet]
---

## まず結論
**β-VAE・infoVAE・VQ-VAEはすべてVAEの改良版だが、改良ポイントがまったく違う**。  
G検定では「**何を改善したモデルか**」を見抜ければ即答できる。

---

## 直感的な説明
まず目的が違う。

- **β-VAE**  
  → 潜在変数を「きれいに分けたい」
- **infoVAE**  
  → 学習を「安定させたい」
- **VQ-VAE**  
  → 潜在空間を「離散化したい」

名前が似ているが、  
**触っているポイントが全部違う**。

---

## 定義・仕組み
### 3モデルの役割整理（横並び）

| モデル | 何を変えた？ | 潜在変数 | 主な目的 |
|---|---|---|---|
| β-VAE | KL項に重みβ | 連続 | 解釈性向上 |
| infoVAE | KL項の設計 | 連続 | 学習安定化 |
| VQ-VAE | 潜在表現を量子化 | **離散** | 生成安定性 |

### 各モデルの要点
- **β-VAE**  
  KLダイバージェンスを強めて、  
  潜在変数同士の独立性（ disentanglement ）を高める

- **infoVAE**  
  情報理論的にKL項を見直し、  
  学習の不安定さを改善

- **VQ-VAE**  
  潜在空間を **連続 → 離散ベクトル** に変更  
  （Vector Quantization）

G検定では  
**「どこをいじったVAEか」**が判断軸。

---

## いつ使う？（得意・不得意）
### β-VAEが向く場面
- 潜在変数の意味を解釈したい
- 因子分解的な表現が欲しい

### infoVAEが向く場面
- VAEの学習が不安定
- KL項の影響を調整したい

### VQ-VAEが向く場面
- 画像・音声生成
- 潜在表現の安定性が重要
- 実用的な生成モデル

👉 **実用寄り：VQ-VAE  
研究・解析寄り：β-VAE / infoVAE**

---

## G検定ひっかけポイント
ここが得点差。

### よくある混同
- ❌ β-VAEは潜在空間を離散化する  
- ❌ infoVAEは条件付きVAE  
- ❌ VQ-VAEはKL項を強めたモデル  

👉 **全部不正解**。

### 選択肢の切り方（即断基準）
- 「潜在変数の独立性・解釈性」  
  → **β-VAE**
- 「KL項の再設計・学習安定性」  
  → **infoVAE**
- 「連続ではなく離散ベクトル」  
  → **VQ-VAE**

キーワードで切る。

---

## まとめ（試験直前用）
- 3つともVAEの派生
- β-VAE＝解釈性重視
- infoVAE＝学習安定性重視
- VQ-VAE＝潜在空間の離散化
- 「何を改善した？」で即切り
