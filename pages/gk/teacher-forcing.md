---
layout: page
title: 教師強制（Teacher Forcing）とは？【RNN・系列モデルの学習手法｜G検定対策】
permalink: /gk/teacher-forcing/
tags: [gk, rnn, neural_network]
gk_section: ディープラーニングの要素技術/リカレントニューラルネットワーク (RNN)
gk_order: 14
---

## まず結論
- **教師強制（teacher forcing）とは、系列モデルの学習時に「モデルの出力」ではなく「正解ラベル」を次の入力として与える学習手法**である。
- G検定では「**誤差を蓄積させないための工夫**」として問われる。

## 直感的な説明
系列モデル（RNN / LSTMなど）では、本来

> 前の出力 → 次の入力

という流れで処理します。

しかし学習初期は、
- 出力がズレる
- そのズレが次に伝播
- **誤差がどんどん蓄積**

してしまいます。

そこで teacher forcing では、

> **前の出力の代わりに、正解を入力する**

ことで、  
**強制的に正しい道を歩かせる**のです。

## 定義・仕組み
### 教師強制（Teacher Forcing）の定義
- 主に **系列予測・言語生成モデル**で用いられる学習手法
- 学習時において、
  - ❌ モデルの出力
  - ⭕ 正解ラベル
を次ステップの入力として使用する

### 目的
- 学習の安定化
- 収束の高速化
- 誤差の蓄積（exposure bias）の抑制

重要：
- **学習時のみ使用**
- 推論時（テスト時）は使えない

## いつ使う？（得意・不得意）
### 得意な場面
- RNN / LSTM / GRU
- 機械翻訳
- 言語生成
- 時系列予測

### 注意が必要な点
- 推論時は teacher forcing が使えない
- 学習と推論の挙動が異なる（exposure bias）
- 完全に依存すると汎化が弱くなることも

## G検定ひっかけポイント
ここが今回の問題の核心です。

### よくある誤解
- ❌「モデルの出力を次の入力にする」
- ❌「誤りを蓄積させる手法」
- ❌「強化学習の手法」
- ❌「Q値を固定する方法」

### 正しい判断基準
- **正解ラベルを次の入力に使う → 教師強制**
- **モデルの出力を使う → 自由生成（free running）**
- **強化学習の話 → 無関係**

問題文に  
「正解ラベルを次の入力」  
「誤差の蓄積を防ぐ」  
とあれば **teacher forcing**。

## まとめ（試験直前用）
- teacher forcing＝正解を入力
- 系列モデルの学習手法
- 誤差の蓄積を防ぐ
- 学習時のみ使用
- 「正解を強制」がキーワード
