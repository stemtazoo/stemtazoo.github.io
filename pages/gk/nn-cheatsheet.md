---
layout: page
title: ニューラルネットワーク総まとめ（チートシート）
permalink: /gk/nn-cheatsheet/
tags: [gk, neural_network, cheatsheet]
gk_section: チートシート（試験直前）/チートシート（試験直前）
gk_order: 1
---

## まず結論

* **ニューラルネットワークは「構造 × 学習 × 汎化」で整理する**
* MLP / CNN / RNN は **扱うデータ構造の違い**
* G検定では **用語の対応関係を即答できるか** が勝負

---

## 直感的な全体像

ニューラルネットワークは、

> 「どんな形のデータを、どう学習し、どう失敗を防ぐか」

で整理すると一気に見通しが良くなります。

---

## 構造の整理（何を扱う？）

| モデル     | 主な用途    | キーワード     |
| ------- | ------- | --------- |
| パーセプトロン | 線形分類    | XOR不可     |
| MLP     | 表形式データ  | 全結合       |
| CNN     | 画像・空間構造 | 畳み込み・重み共有 |
| RNN     | 時系列・系列  | 内部状態      |
| LSTM    | 長期依存    | ゲート・セル状態  |
| GRU     | 軽量RNN   | ゲート2つ     |

---

## 学習の仕組み（どう学ぶ？）

### 基本フロー

1. 順伝播（Forward）
2. 誤差計算（Loss）
3. 逆伝播（Backpropagation）
4. 最適化（Optimizer）

---

### 活性化関数

| 使う場所     | 関数      | ポイント     |
| -------- | ------- | -------- |
| 中間層      | ReLU系   | 勾配消失しにくい |
| 出力（二値）   | Sigmoid | 確率       |
| 出力（多クラス） | Softmax | 和が1      |

---

### 最適化手法

| 手法       | 特徴      |
| -------- | ------- |
| SGD      | 基本      |
| Momentum | 安定化     |
| Adam     | 定番・実務向け |

---

## 汎化性能（失敗を防ぐ）

### 過学習対策

| 手法             | 目的     |
| -------------- | ------ |
| L1             | 特徴選択   |
| L2             | 重み抑制   |
| Dropout        | NN定番   |
| Early Stopping | 学習回数制御 |

---

## バッチ系用語まとめ

| 用語      | 意味      |
| ------- | ------- |
| バッチ     | 全データ    |
| ミニバッチ   | 小分け（主流） |
| エポック    | データ周回数  |
| イテレーション | 更新回数    |

---

## CNNひっかけ即答

* フィルタは **学習される**
* プーリングは **学習されない**
* 重み共有でパラメータ削減

---

## RNNひっかけ即答

* 勾配消失・爆発が起きやすい
* LSTM / GRU は **勾配消失対策**
* LSTM：ゲート3・セル状態あり
* GRU：ゲート2・セル状態なし

---

## 試験直前チェックリスト

* XORが解けない → パーセプトロン
* 画像 → CNN
* 時系列 → RNN / LSTM / GRU
* 多クラス分類 → Softmax
* 定番Optimizer → Adam

---

## まとめ（本番直前）

* NNは **構造・学習・汎化** で整理
* モデル名と特徴を1対1で覚える
* 迷ったら「データの形」で判断

👉 この1ページを最後に見返せば、NN分野は盤石です。
