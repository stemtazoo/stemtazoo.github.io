---
layout: page
title: ディープフェイク検出技術とは？【G検定対策】
permalink: /gk/deepfake-detection/
tags: [gk, ethics, social_issues]
---

## まず結論
- **ディープフェイク検出技術**とは、**AIによって生成された偽の画像・音声・動画を識別・検出するための技術**である。
- G検定では **「AIで生成されたものを、AIで見抜く」点**と、**完全防止は困難**という前提が問われる。

## 直感的な説明
- 人の目では見抜けないほど精巧な偽映像でも、
  - 不自然なクセ
  - 人間では気づきにくい特徴  
  をAIが検出する。
- **偽札検出器のような役割**と考えると分かりやすい。

## 定義・仕組み
ディープフェイク検出は主に次のアプローチで行われる。

### ① 画像・動画の特徴分析
- 顔の輪郭の不自然さ
- まばたき頻度の異常
- 影・光源の不整合
- フレーム間の不連続性

### ② 音声の特徴分析
- 声の周波数成分の不自然さ
- 話速・抑揚の不一致

### ③ 機械学習・深層学習
- 本物／偽物の大量データで学習
- CNNやTransformerを用いた分類

👉 **生成モデルと検出モデルのいたちごっこ**になりやすい。

## いつ使う？（得意・不得意）
**使われる場面**
- SNSプラットフォーム
- 報道機関
- 選挙・政治分野

**苦手な点**
- 新しい生成手法への即時対応
- 完全な真偽保証

## G検定ひっかけポイント
- ❌「ディープフェイクは完全に技術で防げる」
- ❌「検出技術があればフェイク問題は解決する」
- ❌「政府が強制的に全削除できる」

👉 **検出は可能だが、完全ではない**

### 判断基準
- 技術的対策 → ⭕
- 完全防止・ゼロリスク → ❌
- 制度・教育との併用 → ⭕

## まとめ（試験直前用）
- ディープフェイクは検出可能
- AIがAIを見抜く構造
- 画像・音声・動画が対象
- いたちごっこになりやすい
- 技術＋制度＋教育が重要
