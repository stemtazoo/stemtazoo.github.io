---
layout: page
title: AICとBICの違いまとめ（モデル選択）
permalink: /gk/aic-bic/
tags: [gk, metrics, cheatsheet]
gk_section: 機械学習の概要/モデルの選択・評価
gk_order: 17
---

## まず結論

AICとBICはどちらも**モデル選択のための情報量基準**で、**複雑さへのペナルティの強さが違う**だけです。
G検定では「**どちらがよりシンプルなモデルを選ぶか**」が問われます。

## 直感的な説明

AICとBICは、モデルを評価する**審査員の性格の違い**と考えると覚えやすいです。

* **AIC**：そこそこ厳しい（当てはまりも重視）
* **BIC**：かなり厳しい（シンプル最優先）

データが増えるほど、BICは

> 「余計なパラメータは絶対に許さない」

という姿勢になります。

## 定義・仕組み

それぞれの定義式は次の通りです。

```
AIC = -2 log L + 2k
BIC = -2 log L + k log n
```

* **L**：尤度（当てはまり）
* **k**：パラメータ数
* **n**：データ数

**違いの本質**

* AIC：ペナルティは一定（2k）
* BIC：データ数が多いほどペナルティ増大（k log n）

👉 **どちらも「小さいほど良い」** 指標です。

## いつ使う？（得意・不得意）

**AICが向いている場合**

* 多少複雑でも予測性能を重視したい
* データ数がそれほど多くない

**BICが向いている場合**

* データ数が多い
* 本当に必要な変数だけを選びたい

※ どちらも「精度指標」ではありません。

## G検定ひっかけポイント

G検定では、次のような形で混同させてきます。

* AIC / BIC を **Accuracy や ROC曲線と並べる**
* 「精度を評価する指標」と書いてくる

**選択肢の切り方（即判断）**

* モデル設計・モデル選択 → **AIC / BIC**
* 複雑さへのペナルティが強い → **BIC**
* データ数 n が式に出てくる → **BIC**
* 当てはまりも重視 → AIC

## まとめ（試験直前用）

* AIC / BIC は**モデル選択指標**
* 精度指標ではない
* AIC：柔軟、BIC：厳格
* **BICはシンプルなモデルを選びやすい**
* 迷ったら「データ数・ペナルティ」で判断
