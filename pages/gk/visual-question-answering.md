---
layout: page
title: Visual Question Answering（VQA）とは？画像に質問して答えるAI【G検定対策】
permalink: /gk/visual-question-answering/
tags: [gk, vision, nlp]
gk_section: ディープラーニングの応用例/マルチモーダル
gk_order: 9
---

## まず結論
- **Visual Question Answering（VQA）とは、画像を入力として受け取り、その内容に関する自然言語の質問に答えるマルチモーダルAIタスクである。**
- G検定では「**画像生成ではない**」「**翻訳ではない**」点が問われる。

## 直感的な説明
VQAは一言で言うと、

> **「この画像について質問すると、AIが答えてくれる」**

タスクです。

例：
- 画像：「犬がボールをくわえている写真」
- 質問：「犬は何をくわえていますか？」
- 回答：「ボール」

👉 **画像を見る力＋文章を理解する力**  
👉 **両方を同時に使う**のがポイントです。

## 定義・仕組み
### 定義
- 画像（視覚情報）と質問文（言語情報）を入力として、
- それらを統合し、自然言語または選択肢で回答を出力するタスク

### 仕組みの概要
1. CNNやVision Transformerで画像特徴を抽出
2. RNNやTransformerで質問文をエンコード
3. 両者をAttentionなどで統合
4. 回答を生成または分類

重要：
- **画像理解＋言語理解の融合**
- 単なる画像分類でも文章生成でもない

## いつ使う？（得意・不得意）
### 得意な応用例
- 視覚アシスタント
- 教育・医療支援
- ロボットの環境理解
- 視覚障害者支援

### 注意点
- 高品質なアノテーションが必要
- 質問の曖昧さに弱い
- 常識推論が必要な場合は難易度が高い

## G検定ひっかけポイント
ここが一番重要です。

### よくある誤解
- ❌「文章から画像を生成する技術」
- ❌「画像とテキストを翻訳する技術」
- ❌「視覚特徴を使ったクラスタリング」

### 正しい判断基準
- **質問がある → VQA**
- **画像が入力 → VQA**
- **答えが自然言語 → VQA**

問題文に  
「画像を入力」「質問に答える」  
とあれば **VQA**。

## 類似タスクとの違い（超頻出）
- **VQA**：画像＋質問 → 回答
- **画像生成**：テキスト → 画像
- **画像キャプション生成**：画像 → 説明文
- **CLIP**：画像とテキストの対応付け

👉 **「質問があるか？」で切る**

## まとめ（試験直前用）
- VQAは画像に質問して答えるタスク
- 視覚＋言語のマルチモーダルAI
- 画像生成や翻訳ではない
- 質問応答が本質
- G検定の定番ひっかけ
