---
layout: page
title: ニューラルネットワーク最終チートシート（試験直前）
permalink: /gk/nn-final-cheatsheet/
tags: [gk, neural_network, cheatsheet]
gk_section: チートシート（試験直前）/チートシート（試験直前）
gk_order: 2
---

## まず結論（これだけ覚える）

* **データの形でモデルを選ぶ**
* 学習は「誤差逆伝播 × 最適化手法」
* 失敗（過学習・勾配問題）には定番の対策がある

---

## モデル選択 即答表（超重要）

| データの形 | 使うモデル       | 即答キーワード        |
| ----- | ----------- | -------------- |
| 線形分離  | パーセプトロン     | XOR不可          |
| 表形式   | MLP         | 全結合・非線形        |
| 画像    | CNN         | 畳み込み・重み共有      |
| 時系列   | RNN         | 内部状態           |
| 長期依存  | LSTM        | ゲート3・セル状態      |
| 軽量RNN | GRU         | ゲート2           |
| 系列全体  | Transformer | Self-Attention |

---

## 学習の仕組み（どう学ぶ？）

### 基本フロー

1. 順伝播（Forward）
2. 損失計算（Loss）
3. 誤差逆伝播（Backpropagation）
4. 最適化（Optimizer）

---

### 活性化関数 即答

| 使う場所     | 関数      | ひとこと        |
| -------- | ------- | ----------- |
| パーセプトロン  | Step    | 微分不可        |
| 中間層      | ReLU    | 主流・勾配消失しにくい |
| 出力（二値）   | Sigmoid | 確率          |
| 出力（多クラス） | Softmax | 和が1         |

---

### 最適化手法 即答

| 手法       | 覚え方      |
| -------- | -------- |
| SGD      | 基本       |
| Momentum | SGD安定化   |
| Adam     | 定番（まずこれ） |

---

## 汎化性能（失敗を防ぐ）

### 過学習対策

| 手法                | 目的      |
| ----------------- | ------- |
| L1                | 特徴選択    |
| L2                | 重み抑制    |
| Dropout           | NN定番    |
| Early Stopping    | 学習回数制御  |
| Data Augmentation | データ不足対策 |

---

## バッチ系用語 即答

| 用語      | 意味      |
| ------- | ------- |
| バッチ     | 全データ    |
| ミニバッチ   | 小分け（主流） |
| エポック    | データ周回数  |
| イテレーション | 更新回数    |

---

## CNN 即答ゾーン

* フィルタ（カーネル）は **学習される**
* プーリングは **学習されない**
* 重み共有 → パラメータ削減
* 位置ズレに強い

---

## RNN 即答ゾーン

* 勾配消失・勾配爆発が起きやすい
* LSTM / GRU は **勾配消失対策**
* LSTM：ゲート3・セル状態あり
* GRU：ゲート2・セル状態なし

---

## Attention / Transformer 即答

* Attention：**どこに注目するかを学習**
* Q / K / V が基本
* Self-Attention：同一系列内の関係
* Transformer：RNNを使わない系列モデル
* 並列計算・長期依存に強い

---

## Embedding / Word2Vec 即答

* Embedding：意味を持つベクトル表現
* One-Hotより低次元・意味を保持
* Word2Vec：自己教師あり学習
* CBOW：高速・全体的意味
* Skip-gram：低頻度語に強い

---

## 試験直前チェックリスト

* XOR → パーセプトロン不可
* 画像 → CNN
* 時系列 → RNN / LSTM / GRU
* 多クラス分類 → Softmax
* Optimizer迷ったら → Adam

---

## 最後に（本番直前）

* 迷ったら **データの形** に戻る
* モデル名と役割を1対1で思い出す
* この1ページを最後に見る

👉 **ニューラルネットワーク分野はこれで完成です。**
