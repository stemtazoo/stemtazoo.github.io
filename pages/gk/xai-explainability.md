---
layout: page
title: AIモデルの説明可能性（XAIと性能のトレードオフ）
permalink: /gk/xai-explainability/
tags: [gk]
gk_section: ディープラーニングの応用例/モデルの解釈性
gk_order: 1
---

## まず結論

**AIモデルの説明可能性（Explainability）を高めることは重要ですが、
常に「良いことだけ」ではありません。**

G検定での最重要ポイントは次の一文です。

👉 **説明可能性を高めすぎると、知的財産保護の観点で問題になる場合がある**

この「トレードオフ」を理解しているかどうかが問われます。

---

## 直感的な説明

AIモデルには、大きく2つの価値があります。

* **性能**：どれだけ正確に当てられるか
* **説明可能性**：なぜその答えになったかを説明できるか

説明可能性を高めるとは、

* モデルの構造
* 判断の根拠
* 重要な特徴量

を人に分かる形で示すことです。

しかし、

👉 **中身を詳しく説明する＝技術を公開する**

ことにもなり、企業にとってはリスクになる場合があります。

---

## 定義・仕組み

### 説明可能性（Explainability）

* モデルの判断理由を人が理解できること
* 「なぜその予測になったのか」を説明できる性質

### XAI（Explainable AI）

* 説明可能性を高めるための考え方・技術の総称
* 可視化、特徴量重要度、ルール化など

👉 **説明可能AI = XAI**（用語問題として頻出）

---

## いつ考慮する？（得意・不得意）

### 説明可能性が特に重要な場面

* 医療診断
* 金融（融資・与信判断）
* 法律・行政

👉 説明責任が求められる分野

---

### 説明可能性の注意点

* モデル内部を詳しく公開すると

  * 技術が模倣されやすくなる
  * **知的財産の保護が難しくなる**

👉 説明可能性と企業価値はトレードオフ

---

## G検定ひっかけポイント

### ① 「説明可能性は常に高めるべき」

❌ 不正解。

* 高めすぎると知的財産の問題が出る
* すべての用途で最優先ではない

---

### ② ブラックボックス問題＝少数パラメータ

❌ 不正解。

* 少数パラメータでもブラックボックスになり得る
* **多層・複雑なモデルほど説明が難しい**

---

### ③ XAI という用語

* 説明可能AI = **XAI**

👉 用語問題としてそのまま出る

---

## まとめ（試験直前用）

* 説明可能性（Explainability）は AI の重要要素
* **XAI = 説明可能AI**
* 説明可能性を高めすぎると **知的財産保護と衝突**

👉 G検定では

> **説明可能性は重要だが万能ではない**

と覚えておく
