---
layout: page
title: PCAとSVDの関係とは？（数式なしで理解）【G検定対策】
permalink: /gk/pca-vs-svd/
tags: [gk, unsupervised_learning, dimensionality_reduction]
---

## まず結論
- **PCA（主成分分析）は「目的」や「考え方」**,  
  **SVD（特異値分解）は「計算方法（道具）」**であり、  
  **PCAは内部でSVDを使って計算されることが多い**。  
- G検定では「PCAとSVDを別物の手法として切り分けられるか」が問われる。

## 直感的な説明
### PCA（主成分分析）
- 「**情報をできるだけ保ったまま、軸を作り直す**」
- データのばらつきが大きい方向を新しい軸にする
- **何をしたいか？** に注目する考え方

### SVD（特異値分解）
- 「**行列を分解して、中身を整理する**」
- 行列をいくつかの成分に分ける計算手法
- **どうやって計算するか？** に注目する道具

👉  
- **目的・意味** → PCA  
- **計算テクニック** → SVD  

## 定義・仕組み
### PCAの定義
- データの分散が最大となる方向（主成分）を見つけ
- その方向に射影することで
- 次元を削減する手法

### SVDの定義
- 行列を  
  「回転 × 大きさ × 回転」  
  のような形に分解する手法
- 多くの線形代数アルゴリズムの基礎

### 両者の関係
- PCAを実装する際に
- **SVDを使って主成分を計算することが多い**
- ただし  
  **SVDそのもの＝PCAではない**

## いつ使う？（得意・不得意）
### PCAを使う場面
- 特徴量削減
- 可視化（2次元・3次元）
- ノイズ除去
- 前処理としての次元削減

### SVDを使う場面
- 行列分解そのものが目的
- 低ランク近似
- レコメンド（協調フィルタリング）
- PCAの内部計算

👉  
**ユーザーが意識するのは PCA**  
**ライブラリが裏で使うのが SVD**

## G検定ひっかけポイント
- ❌「PCAとSVDはまったく別の次元削減手法」
- ❌「SVDはクラスタリング手法」
- ❌「PCAはSVDの一種」

- ✅「PCAは目的・概念」
- ✅「SVDは計算方法」
- ✅「PCAの実装にSVDが使われる」

**判断基準**
- 「主成分」「分散最大」→ PCA  
- 「行列分解」「特異値」→ SVD  
- 「PCAの計算方法は？」→ SVD  

## まとめ（試験直前用）
- PCA＝何をしたいか（次元削減）
- SVD＝どう計算するか（行列分解）
- PCAの内部でSVDが使われることが多い
- SVD単体はPCAではない
- **PCAとSVDは対立関係ではなく“役割分担”**
