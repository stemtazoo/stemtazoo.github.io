---
layout: page
title: パーセプトロン（Perceptron）
permalink: /gk/perceptron/
tags: [gk, neural_network, perceptron]
---

## まず結論

* **パーセプトロンは最も基本的なニューラルネットワーク**
* **線形分離できる問題のみ解ける**
* **XOR問題は解けない** → これが最大の試験ポイント

---

## 直感的な説明

パーセプトロンは、

> 「複数の入力に重みを掛けて足し算し、ある基準を超えたら1、超えなければ0を出す」

という **とてもシンプルな判定器** です。

イメージとしては、

* 入力：スイッチ（ON / OFF）
* 重み：重要度
* 出力：YES / NO

を決める仕組みだと思えばOKです。

---

## 定義・仕組み

### 基本構造

パーセプトロンは次の計算を行います。

* 入力：(x_1, x_2, ..., x_n)
* 重み：(w_1, w_2, ..., w_n)
* バイアス：(b)

[
\text{出力} = f\left( \sum_i w_i x_i + b \right)
]

ここで使われる活性化関数 (f) は **ステップ関数** です。

* 一定値以上 → 1
* それ以外 → 0

### 学習の考え方

* 正解と違った場合に、重みを少し修正
* この修正を繰り返して、正解に近づける

この考え方が、後の **誤差逆伝播法** の土台になります。

---

## いつ使う？（得意・不得意）

### 得意なこと

* AND / OR のような **線形分離可能な問題**
* 構造が単純で、考え方の理解に最適

### 苦手なこと

* **XOR問題は解けない**
* 複雑なパターン認識には不向き

> XOR問題を解けないことが、
> 「多層化（中間層が必要）」につながる重要な理由です。

---

## G検定ひっかけポイント

* ❌「パーセプトロンはXORを解ける」 → **誤り**
* ❌「非線形問題も解ける」 → **誤り**
* ✅「線形分離可能かどうか」が判断基準
* ✅ 活性化関数は **ステップ関数**
* ✅ 単層パーセプトロン = 中間層なし

特に、

> **XOR問題 → 解けない → 多層パーセプトロンへ**

という流れは、頻出セットです。

---

## まとめ（試験直前用）

* パーセプトロンは **NNの原点**
* **線形分離のみ可能**
* **XORは解けない**（超重要）
* この限界が、多層NN・誤差逆伝播法につながる

👉 次は **多層パーセプトロン（MLP）** を理解すると一気に視界が広がります。
