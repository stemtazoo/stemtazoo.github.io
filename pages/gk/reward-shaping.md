---
layout: page
title: 報酬成形（Reward Shaping）とは？【G検定対策】
permalink: /gk/reward-shaping/
tags: [gk, reinforcement_learning]
---

## まず結論

* **報酬成形（Reward Shaping）**とは、強化学習において学習を加速させるために、**本来の報酬に加えて補助的な報酬を設計・追加する手法**である。
* G検定では「報酬を与えない？」「自動生成？」「学習を遅くする？」といった誤った説明を切れるかが問われる。

## 直感的な説明

* ゴールに到達したときだけ点数がもらえるゲームでは難しすぎるため、
  「ゴールに近づいたら少し点をあげる」ようにするイメージ。
* 正解までの道のりが長いタスクで、**途中経過にヒントを与える**役割を持つ。

## 定義・仕組み

* 本来の環境報酬に対し、人が設計した補助報酬を追加する。
* エージェントは、

  * 最終報酬
  * 補助報酬
    の合計を最大化するように学習する。
* 適切に設計すれば、学習速度が大きく向上する。

## いつ使う？（得意・不得意）

**得意**

* 最終報酬が希薄（スパース）な問題
* ゴールまでのステップが長いタスク

**不得意・注意点**

* 設計を誤ると、本来の目的とズレた行動を学習する
* 報酬ハッキング（Reward Hacking）が起きやすい

## G検定ひっかけポイント

* **「報酬を与えない学習手法」→ ✕**
* **「報酬関数を自動生成する」→ ✕**（それは逆強化学習）
* **「学習を遅らせる」→ ✕**
* キーワードは「補助的な報酬」「学習を早める」

## まとめ（試験直前用）

* 報酬成形＝補助報酬を追加
* 目的は学習の加速
* スパース報酬問題で有効
* 設計ミスに注意
* G検定では定義の切り分けが重要
