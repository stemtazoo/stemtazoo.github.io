---
layout: page
title: スキップグラム（Skip-gram）とは？【G検定対策】
permalink: /gk/skip-gram/
tags: [gk, nlp]
---

## まず結論
- **スキップグラム（Skip-gram）** とは、**ある単語から周囲の単語を予測する word2vec の学習手法**であり、RNNの学習方法ではない。
- G検定では **「教師強制」「RNN」「時系列学習」と混同させる選択肢**がよく出る。

## 直感的な説明
- 文章の中で  
  👉「この単語が出てきたら、近くにどんな単語が出やすい？」  
  を大量に学習する方法。
- 例えば  
  > 「私は**犬**が好き」  
  → 中心語「犬」から「私」「が」「好き」を当てにいくイメージ。

※ **時系列を1ステップずつ処理するRNNとは発想が違う**。

## 定義・仕組み
- スキップグラムは **word2vec の2つの代表的手法の1つ**。
  - **CBOW**：周囲 → 中心語
  - **Skip-gram**：中心語 → 周囲
- ニューラルネットワークを用いるが、
  - RNNではない
  - 時系列モデルでもない
  - 教師強制（Teacher Forcing）も使わない

👉 目的は **単語をベクトル（分散表現）に変換すること**。

## いつ使う？（得意・不得意）
**得意**
- 単語の意味的な近さを表現したいとき
- NLPの前処理（単語埋め込み）
- 類義語・意味構造の獲得

**不得意**
- 文の順序が重要なタスク
- 翻訳・要約などの系列生成
- 時系列データの学習

## G検定ひっかけポイント
- ❌「RNNの学習手法である」
- ❌「各タイムステップで教師データを与える」
- ❌「時系列モデルの一種」

👉 **「単語埋め込み」「word2vec」「周囲単語予測」** がキーワード。

### 判断基準
- **単語ベクトルを作る話 → Skip-gram**
- **時系列・RNN・Encoder-Decoder → 別物**

## まとめ（試験直前用）
- スキップグラムは **word2vec の手法**
- **中心語 → 周囲語** を予測する
- RNNでも教師強制でもない
- NLPの前処理（単語埋め込み）
- 「RNN学習法」と書いてあったら×
