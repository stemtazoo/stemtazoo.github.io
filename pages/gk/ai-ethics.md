---
layout: page
title: AI倫理まとめ（G検定対策）
permalink: /gk/ai-ethics/
tags: [gk, ethics, cheatsheet]
gk_section: AIの法律と倫理/AIの法律と倫理
gk_order: 9
---

## まず結論

* **G検定のAI倫理は「3本柱」で整理すると強い**

  * 公平性（Fairness）
  * 説明可能性（Explainability / XAI）
  * プライバシー（Privacy）
* 技術そのものより **社会への影響と扱い方** が問われる

---

## 直感的な全体像

AI倫理は、

> 「AIを使っても、人が不利益を受けないか？」

という視点で考えます。

* 正しい結果でも
* 公平でなければNG
* 説明できなければNG
* 個人情報を侵害すればNG

---

## ① 公平性（Fairness）

### 何が問題になる？

* 特定の属性だけ不利になる
* 学習データの偏りが原因

**例**

* 採用AIが特定の性別を排除
* 顔認識が特定人種で誤認識

---

### 対策の考え方

* データの偏りを減らす
* 属性ごとの性能を評価

---

## ② 説明可能性（Explainability / XAI）

### なぜ必要？

* なぜその判断になったのか分からない
* ブラックボックス問題

---

### 代表的な考え方

* **XAI（Explainable AI）**
* モデルの判断根拠を人に説明

**注意点**

* 説明性 ↑ → 知的財産リスク ↑

---

## ③ プライバシー（Privacy）

### 関連キーワード

* 個人情報
* 仮名加工情報
* 匿名加工情報

---

### 重要な切り分け

* 社内利用 → 仮名加工情報
* 外部提供 → 匿名加工情報

---

## G検定ひっかけポイント

* ❌「精度が高ければ倫理的に問題ない」→ **誤り**
* ❌「説明できるAIは常に安全」→ **誤り**
* ❌「匿名化すれば何でもOK」→ **誤り**

---

## まとめ（試験直前用）

* AI倫理は **公平性・説明可能性・プライバシー**
* 技術より社会的影響を見る
* 法務分野とセットで覚える

👉 次は **法務・倫理ひっかけ問題集（総集編）** に進むと完成です。
