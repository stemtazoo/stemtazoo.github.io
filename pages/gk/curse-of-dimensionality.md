---
layout: page
title: 次元の呪い（Curse of Dimensionality）とは？G検定対策
permalink: /gk/curse-of-dimensionality/
tags: [gk, machine_learning]
gk_section: 人工知能をめぐる動向/人工知能をめぐる動向
gk_order: 13
---

## まず結論

* **次元の呪い（Curse of Dimensionality）**とは、**特徴量（次元）が増えるほど、データが疎になり、学習や探索が極端に難しくなる現象**です。
* G検定では、**「なぜ高次元データが難しいのか」**を正しく説明できるかが問われます。

## 直感的な説明

* 1次元では「線」、2次元では「面」、3次元では「空間」を考えます。
* 次元が1つ増えるだけで、
  **空間の広さ（体積）が爆発的に増加**します。

👉 その結果、

* データ点同士が遠くなる
* 「近いデータ」という概念が曖昧になる
* 学習に必要なデータ数が急増する

という問題が起きます。

## 定義・仕組み

* 次元の呪いは、

  * 特徴量数の増加
  * 高次元空間の体積の急増
    によって生じます。

* 代表的な影響：

  * **距離尺度が意味を持ちにくくなる**（最近傍探索が不安定）
  * **過学習が起きやすくなる**
  * **計算量が爆発する**

* これは特定のアルゴリズムの欠点ではなく、
  **高次元空間そのものの性質**です。

## いつ使う？（得意・不得意）

### 問題になる場面

* k近傍法（k-NN）
* クラスタリング
* 距離ベースの探索・類似度計算
* 探索空間が指数的に増える問題

### 注意点

* データ数を増やせば完全に解決するわけではない
* 不要な特徴量が多いほど影響が大きい

## G検定ひっかけポイント

* ❌ **次元が高いと精度が必ず向上する**

* ❌ **計算機性能が高ければ解決する問題**

* ⭕ **高次元になるとデータが疎になる**

* ⭕ **距離や近さの概念が崩れる**

👉 「**データが疎になる**」「**距離が意味を失う**」が正解キーワード。

## 対策（試験でよく問われる）

* **次元削減**（PCA など）
* **特徴選択**（重要な特徴だけ残す）
* **正則化**（L1 / L2）

※ これらは“呪いを弱める”対策であり、完全に消せるわけではありません。

## まとめ（試験直前用）

* 次元の呪い＝高次元で学習・探索が困難になる現象
* 原因は空間体積の爆発的増加
* データが疎になり距離が不安定
* 距離ベース手法で特に問題
* 次元削減・特徴選択が代表的対策
* 
