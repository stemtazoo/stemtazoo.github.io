---
layout: page
title: Vision Transformer（ViT）とは？CNNとの違い【G検定対策】
permalink: /gk/vit/
tags: [gk, transformer, attention]
---

## まず結論

* **Vision Transformer（ViT）** とは、画像を小さなパッチ（patch）に分割して「単語（トークン）」のように扱い、**Transformerのエンコーダ（Encoder）**で画像認識を行うモデルである
* G検定では「**CNNとの違い**」「**なぜ話題になったか（大規模事前学習）**」「**パッチ＝トークン**」がよく問われる

---

## 直感的な説明

* CNNは、画像の上を小さなフィルタでなぞって「局所的な特徴（エッジなど）」を積み上げて理解する
* ViTは、画像をタイル状に切り分けて「単語の列」だと思い、**単語同士の関係（Attention）**を見て全体を理解する

イメージ：

* **CNN**：近所（周辺のピクセル）から順に理解して、最後に全体像へ
* **ViT**：最初から全体のパッチ同士を見比べて、重要な関係を学ぶ

G検定では「**局所から積むのがCNN / 全体の関係を直接見るのがViT**」が第一の分岐になる。

---

## 定義・仕組み

### ViTの流れ（ざっくり）

1. 画像を固定サイズのパッチに分割（例：16×16）
2. 各パッチをベクトルに変換（パッチ埋め込み / patch embedding）
3. パッチの並び順を表す **位置埋め込み（positional embedding）** を足す
4. Transformer **Encoder** に入力して特徴を抽出
5. 分類なら [CLS] トークンなどの表現からクラスを予測

### 重要キーワード

* **patch（画像パッチ）**：画像を小分けにした単位（＝トークン）
* **Self-Attention（自己注意）**：パッチ同士の関係を学ぶ仕組み
* **Encoder（エンコーダ）**：ViTで主に使うTransformer側（NLPのBERT側に近い）

※ G検定では数式よりも、
「**画像→パッチ→トークン列→Encoder**」の変換イメージが最重要。

---

## いつ使う？（得意・不得意）

### 得意

* 大規模データで事前学習できると強い（ImageNetよりさらに大きいデータなど）
* 画像全体の関係性（遠く離れたパーツ同士）を捉えやすい
* Transformer系の発展（学習スケール、転移、自己教師あり）に乗りやすい

### 不得意

* 学習データが少ないとCNNより不利になりやすい（データ効率が悪いと言われがち）
* Attentionの計算量が大きくなりやすい（パッチ数が増えるほど重い）

G検定では「**ViTは大規模事前学習で強くなる**」が頻出。

---

## G検定ひっかけポイント

### ひっかけ①：ViT＝CNNの置き換え、ではない

* ❌ 「ViTはCNNより常に優れる」
* ✅ **大規模事前学習があると強い**（条件つき）

### ひっかけ②：Transformerのどこを使う？

* ❌ 「Decoderを使う」
* ✅ **Encoderを使う**（画像パッチ列を入力して特徴抽出）

### ひっかけ③：パッチを何として扱う？

* ❌ 「フィルタ処理した特徴マップ」
* ✅ **単語（トークン）**として扱う

### 選択肢の判断基準

* 「**画像パッチを単語のように扱う**」→ ViT
* 「**Self-Attentionで画像を処理**」→ ViT / Transformer系（特にViT）
* 「**局所特徴を畳み込みで抽出**」→ CNN
* 「**JFT-300Mで事前学習**」→ ViT（代表例としてよく出る）

---

## まとめ（試験直前用）

* ViT＝画像を**パッチ→トークン列**にしてTransformer **Encoder**で処理
* CNN＝畳み込みで**局所特徴を積み上げる**
* ViTは**大規模事前学習**があると強い（JFT-300M など）
* キーワード：patch / token / self-attention / encoder
* 「パッチを単語扱い」が出たらViTを疑う
