---
layout: page
title: Agent57（強化学習エージェント）とは？【G検定対策】
permalink: /gk/agent57/
tags: [gk, neural_network]
gk_section: ディープラーニングの応用例/深層強化学習
gk_order: 10
---

## まず結論
- **Agent57 は、:contentReference[oaicite:0]{index=0} が開発した強化学習エージェントで、57種類すべての Atari ゲームで人間平均を超えた初のモデル**。
- G検定では「**何の分野のモデルか**」「**何がすごいのか**」を問われる。

## 直感的な説明
- Agent57 は「**ゲームが変わっても賢く立ち回れる万能ゲーマー**」。
- 普通の強化学習：
  - 1つのゲームに特化して上達する
- Agent57：
  - ゲームごとに戦い方を切り替え
  - 過去の成功体験を思い出しながら探索
- 人間で言うと：
  - 「このゲームは慎重に」
  - 「こっちは大胆に」
  と**性格を切り替えるプレイヤー**。

## 定義・仕組み
- Agent57 は **強化学習（Reinforcement Learning）エージェント**。
- 特徴的な仕組み：
  - **複数のポリシー（行動方針）を使い分ける**
  - **エピソディックメモリ**で過去の良い体験を記憶
  - 探索と活用のバランスを自動調整
- これにより：
  - 報酬が少ないゲームでも学習可能
  - ゲームごとに適応できる高い汎用性を実現

## いつ使う？（得意・不得意）
**得意**
- Atari などのゲーム環境
- 複数タスクを横断する強化学習
- 汎用的なエージェント研究

**不得意・注意**
- 自然言語処理モデルではない
- 画像のセマンティックセグメンテーションとも無関係
- クラスタリング手法でもない

## G検定ひっかけポイント
- **分野混同が最大の罠**
- よくある誤解：
  - ❌ BERT や GPT のような言語モデル
  - ❌ セマンティックセグメンテーションモデル
  - ❌ クラスタリング手法
- 正しい判断基準：
  - 「Atari」「報酬」「行動」「探索」 → **強化学習**
- 選択肢で切るコツ：
  - 「文法」「文章」→ NLP → ❌
  - 「画素」「ラベル」→ 画像処理 → ❌
  - 「報酬最大化」→ **Agent57 ⭕**

## まとめ（試験直前用）
- Agent57 = **強化学習エージェント**
- 57種類すべての Atari ゲームで人間超え
- 複数ポリシー＋エピソディックメモリが特徴
- NLP・画像処理・クラスタリングではない
- **「Atari × 強化学習」＝ Agent57**
- 
