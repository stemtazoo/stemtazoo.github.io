---
layout: page
title: A2C / A3C とは？（Actor–Critic の実装差）【G検定対策】
permalink: /gk/a2c-a3c/
tags: [gk, neural_network]
gk_section: 機械学習の概要/代表的な手法/強化学習
gk_order: 8
---

## まず結論
- **A2C と A3C は、Actor–Critic をベースにしたオンポリシー強化学習アルゴリズム**。
- 両者の違いは **「同期（A2C）か非同期（A3C）か」**。

## 直感的な説明
- A3C：
  - 複数人が**バラバラに練習**
  - 気づいたことをその都度共有
- A2C：
  - 複数人が**足並みをそろえて練習**
  - まとめて結果を反映
- どちらも：
  - Actor が行動
  - Critic が評価
  - **Advantage（どれだけ良かったか）**を使う

## 定義・仕組み
### 共通点（A2C / A3C）
- Actor–Critic 構造
- オンポリシー学習
- Advantage を利用
  - A(s, a) = Q(s, a) − V(s)
- 方策勾配の分散を抑えて安定化

### A3C（Asynchronous Advantage Actor–Critic）
- 特徴：
  - **非同期学習**
  - 複数の Actor が独立に学習
- メリット：
  - 探索の多様性が高い
  - 勾配消失・局所解を避けやすい
- デメリット：
  - 実装が複雑
  - GPU との相性が悪い

### A2C（Advantage Actor–Critic）
- 特徴：
  - **同期学習**
  - 複数環境を並列実行
- メリット：
  - 実装がシンプル
  - GPU に向いている
- デメリット：
  - 探索の多様性は A3C より低い

## いつ使う？（得意・不得意）
**A3C が向いている**
- CPU 並列環境
- 探索多様性を重視

**A2C が向いている**
- GPU 環境
- 実装・再現性重視

## G検定ひっかけポイント
- **A2C / A3C をオン／オフで迷わせる**
- よくある誤解：
  - ❌ A3C はオフポリシー
  - ❌ A2C は DQN 系
- 正しい理解：
  - ⭕ 両方ともオンポリシー
  - ⭕ Replay は使わない
- 即断キーワード：
  - 「非同期」→ A3C
  - 「同期」→ A2C
  - 「Advantage」→ A2C / A3C

## まとめ（試験直前用）
- A2C / A3C は Actor–Critic 系
- 両方オンポリシー
- A3C：非同期・探索多様
- A2C：同期・実装安定
- **違いは同期方式**
