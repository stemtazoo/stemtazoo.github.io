---

layout: page
title: ビッグデータとは？G検定対策
permalink: /gk/big-data/
tags: [gk]
----------

## まず結論

ビッグデータとは、**従来のデータ処理技術では扱いきれないほど「量・多様性・速度」をもつデータ**の総称です。
G検定では、**データの特徴や分類（構造化／非構造化）を正しく理解しているか**が問われます。

## 直感的な説明

ビッグデータは「**巨大で、種類がバラバラで、どんどん増えるデータの山**」だと考えると分かりやすいです。

* 表形式のデータ（売上、ログ）
* 文章、画像、音声、動画
* SNS投稿やセンサーデータ

これらが**大量かつ高速に発生**するため、人手や従来型DBでは扱えなくなります。

## 定義・仕組み

ビッグデータは、次の **3V（または5V）** で説明されることが多いです。

* **Volume（量）**：非常にデータ量が多い
* **Variety（多様性）**：形式がバラバラ
* **Velocity（速度）**：生成・更新が速い

補足として次が加えられることもあります。

* **Veracity（正確性）**
* **Value（価値）**

また、データの形式によって次のように分類されます。

* **構造化データ**：表形式（CSV、RDB）
* **半構造化データ**：JSON、XML
* **非構造化データ**：文章、画像、音声、動画

## いつ使う？（得意・不得意）

**使われる場面**

* 検索エンジン、推薦システム
* SNS分析、ログ分析
* IoT・センサーデータ解析

**注意点・課題**

* データ量が多く、保守管理や運用負荷は高い
* 前処理・基盤構築が重要

## G検定ひっかけポイント

G検定では、次の誤解を狙われます。

* **「更新頻度が低い」と書かれている**
* **「保守管理や運用負荷が低い」と書かれている**
* **AIブームの原因を取り違える**

**正しい判断基準**

* 更新頻度 → **高いことが多い**
* 運用負荷 → **一般に高い**
* ビッグデータは**第3次AIブームの要因**

## まとめ（試験直前用）

* ビッグデータ＝大量・多様・高速なデータ
* 構造化／半構造化／非構造化に分類される
* 更新頻度は低くない
* 保守・運用負荷はむしろ高い
* 第3次AIブームを支えた要因の1つ

