---
layout: page
title: Dilated Convolution（空洞畳み込み）
permalink: /gk/dilated-convolution/
tags: [gk, neural_network, cnn]
---

## まず結論

* **Dilated Convolution は受容野を広げられる畳み込み**
* **プーリングを使わずに特徴マップの解像度を保てる**
* **画像サイズを小さくしないことが最大のメリット**

---

## 直感的な説明

Dilated Convolution は、

> **カーネルの間隔をあけて畳み込む手法**

です。

通常の畳み込みは、  
ピクセルを「隣同士」で見ますが、  
Dilated Convolution は

* 1つ飛ばし
* 2つ飛ばし

のように **間隔をあけて見る** イメージです。

---

## 定義・仕組み

### 通常の畳み込みとの違い

* 通常の畳み込み  
  → 連続したピクセルを処理
* Dilated Convolution  
  → **間隔（dilation rate）をあけて処理**

これにより、

* パラメータ数を増やさず
* 広い範囲（大域的情報）を捉えられる

という特徴があります。

---

### 重要なポイント

* **ストライドは変えない**
* **プーリングを使わない**
* → その結果  
  **画像サイズ（解像度）が保たれる**

---

## いつ使う？（得意・不得意）

### 得意なこと

* セマンティックセグメンテーション
* 画像の文脈（広い範囲）理解
* 境界情報を保ちたいタスク

（例：道路・建物・人物領域の判定）

---

### 注意点・不得意

* 学習が速くなるわけではない
* 局所的な細かい特徴だけを見る用途には不向き

---

## G検定ひっかけポイント

ここが**超重要**です👇

### ❌ よくある誤解

* ❌ **「学習速度が向上する」**
* ❌ **「より局所的な情報を扱える」**

👉 **どちらも誤り**

---

### ✅ 正しい理解

* ✅ **受容野が広がる（大域的情報）**
* ✅ **画像サイズを小さくしない**
* ✅ プーリングの代替として使われることが多い

---

### 試験での即切りフレーズ

* 「サイズを保つ」  
* 「プーリングなしで広い範囲」  

👉 **Dilated Convolution**

---

## 他の手法との違い（整理）

| 手法 | サイズ | 見る範囲 |
|---|---|---|
| 通常Conv | 変わらない | 局所 |
| Pooling | 小さくなる | 広がるが粗い |
| Dilated Conv | **変わらない** | **広い** |

---

## まとめ（試験直前用）

* Dilated Convolution = **間隔をあけた畳み込み**
* 目的は **受容野拡大**
* **画像サイズを小さくしない**
* 学習速度UPではない

👉 次は  
**Atrous Spatial Pyramid Pooling（ASPP）**  
との関係がよく問われます。

