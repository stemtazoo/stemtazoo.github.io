---
layout: page
title: AI倫理まとめ（XAI・公平性・プライバシー）
permalink: /gk/ai-ethics-cheatsheet/
tags: [gk, cheatsheet]
---

## まず結論（この1ページで即断）

G検定で「AIの社会的側面・倫理」が出たら、
**見るべき観点は次の3つだけ**です。

1. **説明できるか？（XAI）**
2. **偏っていないか？（公平性）**
3. **個人を侵害していないか？（プライバシー）**

👉 技術の正しさよりも、**社会的な妥当性**が問われます。

---

## 直感的な全体像

| 観点         | 一言で言うと   | 典型キーワード       |
| ---------- | -------- | ------------- |
| **XAI**    | なぜその判断？  | 説明責任・ブラックボックス |
| **公平性**    | 偏ってない？   | 差別・バイアス       |
| **プライバシー** | 集めすぎてない？ | 個人情報・監視       |

---

## 各要素の要点（最小限）

### 説明可能性（XAI）

* 判断理由を人が理解できること
* 医療・金融などで重要
* **高めすぎると知的財産保護と衝突**

👉 「説明できれば良い」ではない

---

### 公平性（Fairness）

* 特定の属性に不利益を与えない
* データの偏りが原因になりやすい
* 完全な公平は難しい（トレードオフ）

👉 AI は中立ではない

---

### プライバシー・個人情報保護

* 個人を特定できる情報を守る
* 個人情報でなくても侵害になる場合あり
* データ活用と常にトレードオフ

👉 集めすぎない設計が重要

---

## G検定ひっかけ即断表（最重要）

| 問題文の表現      | 注目点    | 正しい判断         |
| ----------- | ------ | ------------- |
| なぜその判断か説明   | XAI    | 説明責任・ブラックボックス |
| 特定の集団に不利    | 公平性    | データバイアス       |
| 顔認証・位置情報    | プライバシー | 個人情報保護        |
| 精度向上のため大量収集 | プライバシー | トレードオフ        |
| 説明可能性を最大化   | XAI    | 知財リスクあり       |

---

## なぜ間違えやすいか

* 技術的に正しい選択肢が並ぶ
* 「常に高めるべき」「すべて解決する」
  といった **極端な表現** が混ざる

👉 **G検定は“バランス感覚”を見る**

---

## まとめ（試験直前用・暗記版）

* **XAI**：説明できるが、知財と衝突する場合あり
* **公平性**：AIは偏る可能性がある
* **プライバシー**：データ活用と常にトレードオフ

👉 迷ったら

> **AIは万能ではなく、社会とのバランスが必要**
