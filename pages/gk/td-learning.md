---
layout: page
title: 差分学習（TD学習, Temporal Difference Learning）とは？G検定対策
permalink: /gk/td-learning/
tags: [gk, reinforcement_learning]
gk_section: ディープラーニングの応用例/深層強化学習
gk_order: 18
---

## まず結論

* **差分学習（TD学習, Temporal Difference Learning）**とは、強化学習において、**現在の予測と次の予測の差（時間差誤差）を用いて価値関数を更新する学習手法**。
* G検定では**「方策を変えたときの予測誤差の差」＝TD学習**と即断できるかが問われる。

## 直感的な説明

* 今日の自分の予想と、

  * 明日になって分かった「次の予想」を比べて
  * 「あ、予想ズレてたな」と少しずつ修正する
* TD学習は、
  👉 **未来を待たずに、途中の予測ズレで学習する方法**です。

## 定義・仕組み

* TD学習では、

  * 状態 s における現在の価値予測
  * 次の状態 s' における価値予測
  * 実際に得られた報酬
    から **時間差誤差（TD誤差）** を計算します。

* ポイント：

  * 最終結果（エピソード終了）を待たない
  * 予測と予測の差で学習する
  * モデルフリー強化学習

* 代表例：

  * Q学習
  * SARSA

## いつ使う？（得意・不得意）

### 使われる場面（得意）

* オンライン学習
* 長いエピソードを持つ問題
* 環境モデルが分からない場合

### 注意点・不得意

* 学習が不安定になることがある
* 方策に依存する（SARSAなど）

## G検定ひっかけポイント

* よくある混同：

  * ❌ 教師あり学習
  * ❌ 状態表現学習
  * ❌ 行動クローニング

* 判断基準：

  * **「現在予測と次予測の差」→ TD学習**
  * **「エピソード終了後にまとめて更新」→ モンテカルロ法**

## まとめ（試験直前用）

* TD学習＝予測と予測の差で学習
* 時間差誤差を利用
* エピソード終了を待たない
* Q学習・SARSAの基礎
* 「差」「予測誤差」がキーワード
