---
layout: page
title: 潜在的ディリクレ配分法（LDA）とは？G検定対策
permalink: /gk/lda/
tags: [gk, nlp]
gk_section: 機械学習の概要/代表的な手法/教師なし学習
gk_order: 15
---

## まず結論

* **潜在的ディリクレ配分法（LDA：Latent Dirichlet Allocation）**とは、文書集合に潜む**トピック（話題）構造**を確率的に推定する**教師なし学習のトピックモデル**。
* G検定では**「教師あり／ディープラーニングではない」**ことを見抜けるかが問われる。

## 直感的な説明

* 1つのニュース記事は、

  * 「政治」だけ
  * 「経済」だけ
    とは限らず、**複数の話題が混ざっている**ことが多いです。
* LDAは、

  * 文書は「トピックの混合」
  * トピックは「単語の分布」
    だと考え、
* 👉 **文章の裏にある話題の割合を推測する**手法です。

## 定義・仕組み

* LDAでは次の仮定を置きます。

  * 各文書は複数トピックの確率分布を持つ
  * 各トピックは単語の確率分布を持つ

* 文書生成の考え方（概念）：

  1. 文書ごとにトピック分布を決める
  2. 単語を出すたびにトピックを選ぶ
  3. そのトピックに対応した単語を生成する

* **ディリクレ分布**は、この「確率分布」を制御するために使われます。

## いつ使う？（得意・不得意）

### 使われる場面（得意）

* 文書クラスタリング
* 話題抽出・要約
* 大量テキストの構造把握

### 注意点・不得意

* 画像分類には使えない
* 教師あり学習ではない
* 深層学習モデルではない

## G検定ひっかけポイント

* よくある誤り表現：

  * ❌ 「教師あり学習で使われる」
  * ❌ 「画像分類のディープラーニングモデル」

* 正しい理解：

  * NLP分野の**教師なし学習**
  * トピックモデル

* 判断基準：

  * **文書・単語・トピック → LDA**
  * **画像・CNN → 別物**

## まとめ（試験直前用）

* LDA＝教師なしトピックモデル
* 文書はトピックの混合
* トピックは単語分布
* 画像分類・DLではない
* 「確率的に話題を推定」がキーワード
