---
layout: page
title: AIの安全性とロバスト性（Safety / Robustness）
permalink: /gk/safety-robustness/
tags: [gk]
---

## まず結論

**AIの安全性・ロバスト性とは、「想定外の入力や環境でも、危険な振る舞いをしないこと」です。**

G検定では、
👉 **「高精度でも、安全でなければ実用できない」**
という考え方を理解しているかが問われます。

---

## 直感的な説明

AIは、

* 学習時に見たデータ
* 想定された使われ方

の範囲ではうまく動きます。

しかし現実では、

* ノイズの入った入力
* 想定外の使い方
* 悪意ある攻撃

が必ず発生します。

👉 **そうした状況でも破綻しないこと**が、安全性・ロバスト性です。

---

## 定義・仕組み

### 安全性（Safety）

* AIが人や社会に**危害を与えない**こと
* 誤作動・誤判断を起こしても
  重大事故につながらない設計

---

### ロバスト性（Robustness）

* ノイズや入力の揺らぎに強い性質
* 少し条件が変わっても
  出力が極端に変わらない

👉 **ロバスト性は安全性の土台**

---

## いつ問題になる？（G検定視点）

### 特に重要な分野

* 自動運転
* 医療診断
* 産業用ロボット
* インフラ制御

👉 失敗が事故につながる分野

---

### よくあるリスク

* ノイズに弱いモデル
* データ分布の変化（データドリフト）
* 想定外入力による誤作動

---

## G検定ひっかけポイント

### ① 精度が高ければ安全

❌ 不正解。

* 高精度でも
* 想定外入力で危険になる場合がある

---

### ② ロバスト性＝万能

❌ 不正解。

* すべての想定外を防ぐことは不可能
* 運用・監視とセットで考える

---

### ③ 倫理・公平性との関係

* 安全性
* 公平性
* 説明可能性
* プライバシー

👉 **すべてトレードオフ関係**

---

## まとめ（試験直前用）

* 安全性：危険な振る舞いをしない
* ロバスト性：ノイズや変化に強い
* **高精度＝安全ではない**

👉 G検定では

> **AIは安全に使えてこそ価値がある**

と覚えておく
