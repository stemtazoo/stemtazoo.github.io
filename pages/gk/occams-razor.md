---
layout: page
title: オッカムの剃刀とは？（Occam's Razor）【G検定対策】
permalink: /gk/occams-razor/
tags: [gk]
gk_section: 機械学習の概要/モデルの選択・評価
gk_order: 20
---

## まず結論

* **オッカムの剃刀（Occam's Razor）**とは、「ある事象を説明するために、**必要以上に多くの仮定を用いるべきではない**」という考え方である
* G検定では「**シンプルなモデルを選ぶべき理由**」として問われ、他の原理との**取り違え**が頻出する

---

## 直感的な説明

同じ結果を説明できるなら、

* 仮定が多くて複雑な説明
* 仮定が少なくてシンプルな説明

**どちらを選ぶべきか？**

→ **シンプルな方**。

これがオッカムの剃刀。
「余計な仮定を“剃り落とす”」というイメージで覚えると分かりやすい。

---

## 定義・仕組み

* オッカムの剃刀は、中世の哲学者 **ウィリアム・オッカム** に由来する原理
* 内容は非常にシンプルで、

  * 説明力が同程度なら
  * **仮定の少ない理論・モデルを選ぶ**

機械学習の文脈では：

* モデルが複雑すぎると
* 過学習（Overfitting）しやすい

→ **単純なモデルの方が汎化性能が高い**

という考え方につながる。

---

## いつ使う？（得意・不得意）

### 使われる場面

* モデル選択
* 仮説検証
* 正則化の考え方

### 注意点

* 「常に単純なモデルが正しい」わけではない
* **説明力が同じ場合に限る**という前提が重要

---

## G検定ひっかけポイント

### よくある混同①：バーニーおじさんのルール

* ❌ 仮定を少なくする原理
* ✅ **必要データ量に関する経験則**

---

### よくある混同②：ノーフリーランチ定理

* ❌ シンプルなモデルが常に有利
* ✅ **どの問題にも万能なモデルは存在しない**という定理

---

### よくある混同③：みにくいアヒルの子定理

* ❌ シンプルさの原理
* ✅ **何らかの仮定なしに分類はできない**という主張

---

### 選択肢の判断基準

* 「**必要以上に多くの仮定を用いない**」→ オッカムの剃刀
* 「**データ量とパラメータ数の関係**」→ バーニーおじさんのルール
* 「**万能なモデルはない**」→ ノーフリーランチ定理
* 「**仮定なしでは分類不能**」→ みにくいアヒルの子定理

---

## まとめ（試験直前用）

* オッカムの剃刀＝**仮定は最小限に**
* シンプルな説明を選ぶ原理
* 過学習防止の考え方につながる
* 他の哲学的原理と混同しやすい
* 「仮定を増やすな」とあれば即これ
