---
layout: page
title: モデル窃取攻撃（Model Extraction Attack）とは？【G検定対策】
permalink: /gk/model-extraction-attack/
tags: [gk, security, privacy]
---

## まず結論
**モデル窃取攻撃（Model Extraction Attack）**とは、  
学習済みAIモデルへの入出力を大量に観測することで、**モデルの挙動や構造を模倣し、同等性能のモデルを再構築する攻撃**である。  
G検定では「データを狙う攻撃」との違いがよく問われる。

---

## 直感的な説明
この攻撃は、  
**「中身をコピーする」というより「動きを真似る」**イメージ。

たとえば、
- ブラックボックスのAIに大量の入力を与える
- 出力結果を記録する
- 入力と出力の関係を学習させる

すると、  
**中の重みや構造を知らなくても、そっくりなAI**が作れてしまう。  
これがモデル窃取攻撃。

---

## 定義・仕組み
**モデル窃取攻撃（Model Extraction / Model Stealing Attack）**とは、

> 公開APIや推論結果を利用して、  
> **対象モデルと同等の予測性能を持つ代替モデルを構築する攻撃**

を指す。

重要なポイント：

- 学習データを直接盗むわけではない  
- モデル内部（重み）を直接取得するわけでもない  
- **入出力関係を学習して再現**する  

G検定では  
「**知的財産の侵害リスク**」という文脈で登場する。

---

## いつ使う？（得意・不得意）
### 成立しやすい状況
- 推論APIが公開されている
- 問い合わせ回数に制限がない
- 出力が詳細（確率・スコアなど）

### 成立しにくい状況
- クエリ制限が厳しい
- 出力が単純（ラベルのみ）
- ノイズ付与・防御策がある場合

👉 **API公開モデル＝モデル窃取のリスクあり**、は重要。

---

## G検定ひっかけポイント
ここで **3つの攻撃の整理** を求められる。

### よくある混同
- ❌ **データ窃取攻撃**  
  → 学習データの一部や特徴を抽出
- ❌ **メンバーシップ推論攻撃**  
  → 学習データに含まれていたかを判定
- ✅ **モデル窃取攻撃**  
  → モデルそのものを模倣・再構築

### 選択肢の切り方
- 「同等性能のモデルを再構築」  
  → **モデル窃取攻撃**
- 「学習データが漏れる」  
  → データ窃取攻撃
- 「含まれていたかを推定」  
  → メンバーシップ推論攻撃

G検定では  
**何を狙っている攻撃か**を見抜く。

---

## まとめ（試験直前用）
- モデル窃取攻撃＝**モデルをコピーする攻撃**
- 入出力関係から模倣モデルを作る
- 学習データは直接狙わない
- データ窃取・メンバーシップ推論と必ず対比
- 「同等性能のモデル構築」→ モデル窃取攻撃
