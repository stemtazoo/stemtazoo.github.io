---
layout: page
title: LIME と SHAP の違い（XAI 深掘り）
permalink: /gk/lime-vs-shap/
tags: [gk, xai, cheatsheet]
---

## まず結論

* **LIME**：局所的・近似的に「その1件」を説明
* **SHAP**：理論的に厳密に「寄与度」を説明
* **速さ・手軽さはLIME、理論的一貫性はSHAP**

👉 G検定では  
**「局所か／寄与度か」** で切る。

---

## 直感的な説明

一言で言うと👇

* LIME  
  → **その予測だけを後付けで説明**
* SHAP  
  → **全特徴量の貢献度を数値で説明**

例えるなら、

* LIME：  
  「この1回の診断で、ここが効いた」
* SHAP：  
  「全体として、この特徴がどれくらい重要」

---

## 定義・仕組み

### LIME（Local Interpretable Model-agnostic Explanations）

* 対象データの周辺を **擬似データで揺らす**
* 単純な線形モデルで近似
* **局所的説明** に特化

👉  
「この入力に対するこの出力」

---

### SHAP（SHapley Additive exPlanations）

* ゲーム理論の **シャープレイ値** を利用
* 各特徴量の **寄与度を公平に分配**
* 理論的保証あり

👉  
「どの特徴がどれくらい効いたか」

---

## LIME と SHAP の違い（超重要）

| 観点 | LIME | SHAP |
|---|---|---|
| 説明範囲 | **局所** | 局所＋大域 |
| 理論的裏付け | 弱い | **強い** |
| 計算コスト | 低い | **高い** |
| 安定性 | ばらつく | **一貫性あり** |
| 実装の手軽さ | ◎ | △ |
| G検定頻度 | 高 | 高 |

---

## いつ使う？（得意・不得意）

### LIME が向く場面

* 1件ごとの判断理由を知りたい
* モデルに依存せず素早く説明
* デバッグ・検証用途

---

### SHAP が向く場面

* 特徴量の重要度を正確に評価
* 説明責任が重い分野（金融・医療）
* 全体傾向の分析

---

## G検定ひっかけポイント

### ❌ よくある誤解

* ❌ 「LIMEは大域的説明が得意」
* ❌ 「SHAPは軽量で高速」
* ❌ 「どちらも同じ考え方」

---

### ✅ 正しい理解

* LIME：近似・局所
* SHAP：寄与度・理論
* **速さ vs 厳密さ**

---

## 試験での即断フレーズ

* 「シャープレイ値」  
  → **SHAP**
* 「局所的な説明」  
  → **LIME**
* 「理論的一貫性」  
  → **SHAP**

---

## まとめ（試験直前用）

* LIME：局所・近似・高速
* SHAP：寄与度・厳密・重い
* 目的が違う
* XAIは精度向上ではない

👉 次は  
**XAI × AI倫理（説明責任・公平性）**  
を押さえると完成です。
