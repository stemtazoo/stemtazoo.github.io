---
layout: page
title: 交差エントロピー誤差（Cross Entropy）とは？【G検定対策】
permalink: /gk/cross-entropy/
tags: [gk, metrics, neural_network]
---

## まず結論
**交差エントロピー誤差（Cross Entropy）**とは、  
**正解ラベルとモデルの予測確率のズレを測る損失関数**であり、  
主に **分類問題（特に多クラス分類）**で使われる。  
G検定では「なぜ分類でよく使われるのか」が問われる。

---

## 直感的な説明
交差エントロピー誤差は、  
**「自信満々で間違えたら、強くペナルティを与える」**評価方法。

たとえば、
- 正解が「犬」
- モデルが「猫：0.9、犬：0.1」と予測

このとき、
> 「間違えただけでなく、自信満々だった」  

ので、  
**誤差はかなり大きくなる**。

逆に、
- 正解に高い確率を出していれば  
- 誤差は小さくなる  

👉 **確率の出し方まで評価する**のがポイント。

---

## 定義・仕組み
**交差エントロピー誤差**とは、

> 正解ラベルの確率分布と、  
> モデルが出力した確率分布の **差（情報量のズレ）** を測る指標

である。

G検定では数式は不要だが、  
理解の軸は次の通り。

- 出力は **確率（Softmaxなど）**
- 正解ラベルは **one-hot表現**
- 正解クラスの確率が低いほど誤差が大きい

👉 **分類 × 確率出力** なら交差エントロピー。

---

## いつ使う？（得意・不得意）
### 得意な場面
- 多クラス分類問題
- ニューラルネットワークの分類タスク
- Softmaxと組み合わせる場合

### 注意・不得意な点
- 回帰問題には使わない
- 確率を出力しないモデルには不向き
- MSE（平均二乗誤差）とは目的が違う

👉 **分類 → 交差エントロピー誤差** が基本。

---

## G検定ひっかけポイント
ここは頻出。

### よくある混同
- ❌ 回帰問題の誤差指標  
- ❌ 正解・不正解だけを見る指標  
- ❌ Accuracy（正解率）と同じ役割  

👉 **全部違う**。

### MSEとの違い（超重要）
- **MSE**  
  → 数値のズレを測る（回帰向き）
- **交差エントロピー誤差**  
  → 確率分布のズレを測る（分類向き）

### 選択肢の切り方
- 「確率分布」「情報量」「分類問題」  
  → **交差エントロピー誤差**
- 「二乗誤差」「回帰」  
  → MSE

---

## まとめ（試験直前用）
- 交差エントロピー誤差＝**分類用の損失関数**
- 正解ラベルと予測確率のズレを評価
- 自信を持って間違えると大きな誤差
- Softmaxとセットで使われる
- 「分類 × 確率」→ 交差エントロピー
