---
layout: page
title: オートエンコーダ（AE）と変分オートエンコーダ（VAE）の違いとは？【G検定対策】
permalink: /gk/ae-vs-vae/
tags: [gk, neural_network]
---

## まず結論
- **AEとVAEの最大の違いは、VAEが「確率モデル」として潜在変数を扱う点**である。
- G検定では「**VAEは確率的、AEは決定的**」という違いを理解しているかが問われる。

## 直感的な説明
### AE（オートエンコーダ）
- 入力をギュッと圧縮
- そのまま元に戻す

👉 **同じ入力 → 同じ出力**  
👉 圧縮と復元だけを学ぶモデル

### VAE（変分オートエンコーダ）
- 圧縮するときに  
  「この辺にありそう」という **分布** を学ぶ
- そこから **確率的にサンプリング** して復元

👉 **同じ入力でも少し違う出力が出ることがある**  
👉 「それっぽい新しいデータ」を作れる

## 定義・仕組み
### AE（Autoencoder）
- エンコーダ：入力 → 潜在表現
- デコーダ：潜在表現 → 元データ
- **決定論的（Deterministic）**
- 損失：再構成誤差のみ

### VAE（Variational Autoencoder）
- 潜在変数を **確率分布（平均と分散）** で表現
- 潜在空間からサンプリングして復元
- **確率モデル**
- 損失：
  - 再構成誤差
  - KLダイバージェンス（分布の制約）

※ 数式理解は不要。  
👉 **「分布を学ぶ」ことが超重要ポイント**

## いつ使う？（得意・不得意）
### AEが得意
- 次元削減
- ノイズ除去
- 異常検知（再構成誤差）

### VAEが得意
- データ生成
- 潜在空間の連続性が欲しい場合
- 未知データへの汎化

### 注意点
- AEは生成が得意ではない
- VAEは再構成精度だけ見るとAEに劣ることがある

## G検定ひっかけポイント
G検定では、次の混同を狙ってきます。

### よくある誤り
- ❌「VAEは説明変数を複数使う」
- ❌「VAEは適合率や再現率の概念を使う」
- ❌「AEとVAEは本質的に同じ」

### 正しい判断基準
- **確率モデル → VAE**
- **分布（平均・分散） → VAE**
- **単純な圧縮と復元 → AE**

問題文に  
「確率」「分布」「サンプリング」  
があれば **VAE** を選ぶ。

## まとめ（試験直前用）
- AE：決定論的・圧縮と復元
- VAE：確率モデル・分布を学ぶ
- VAEは生成が可能
- 最大の違いは「確率かどうか」
- 「確率モデル」→ VAE
