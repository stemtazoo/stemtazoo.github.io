---
layout: page
title: プルーニング（Pruning）
permalink: /gk/pruning/
tags: [gk, neural_network, model_compression]
gk_section: ディープラーニングの概要/ニューラルネットワークとディープラーニング
gk_order: 8
---

## まず結論

* **プルーニングは不要な重み・ニューロンを削除してモデルを軽量化する手法**
* **モデル圧縮・推論高速化** が主目的
* 学習後に適用されることが多い

---

## 直感的な説明

プルーニングは、

> 「ほとんど使われていない配線を切って、スリムにする」

イメージです。

学習済みニューラルネットワークには、

* 出力にほとんど影響しない重み
* ほぼ使われていないニューロン

が含まれています。

それらを **削除（剪定）** することで、

* 軽く
* 速く
* メモリ効率の良い

モデルにできます。

---

## 定義・仕組み

### プルーニングとは

ニューラルネットワークにおいて、

* **重みが小さいパラメータ**
* **重要度の低いニューロンや接続**

を削除することで、

* モデルサイズ削減
* 推論速度向上

を実現する手法です。

---

### 主なプルーニングの種類

#### 重みプルーニング

* 絶対値の小さい重みを 0 にする
* パラメータ数を直接削減

#### ニューロンプルーニング

* 出力への寄与が小さいニューロンを削除

#### 構造化プルーニング

* チャネルやフィルタ単位で削除
* 実装・高速化しやすい

---

## いつ使う？（得意・不得意）

### 得意な場面

* エッジデバイスへのモデル展開
* 推論速度・省メモリが重要な場合
* 学習済みモデルの後処理

### 注意点

* 削除しすぎると **精度低下**
* 再学習（ファインチューニング）が必要なことが多い

---

## G検定ひっかけポイント

* ❌「学習中にランダムにニューロンを無効化する」→ **Dropout**
* ❌「大きな重みにペナルティを課す」→ **正則化（Weight Decay）**
* ✅ プルーニングは **モデル圧縮手法**
* ✅ 主に **学習後に適用**

---

## まとめ（試験直前用）

* プルーニング＝**不要な重み・ニューロンの削除**
* 目的は **モデル軽量化・高速化**
* Dropout や 正則化とは役割が異なる
