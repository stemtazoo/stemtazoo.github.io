---
layout: page
title: 物体検出とセグメンテーションの違い【G検定体系図】
permalink: /gk/detection-segmentation-map/
tags: [gk, cnn, cheatsheet]
gk_section: ディープラーニングの応用例/画像認識/ネオコグニトロンとLeNet
gk_order: 14
---

## まず結論

* **物体検出とセグメンテーションは「出力の粒度」が違う**
* G検定では「**四角か？ピクセルか？個体を区別するか？**」で切り分ける

---

## 直感的な説明

画像認識タスクは、次のようにレベル分けできる。

* **画像分類**：

  * 写真に「何が写っているか」だけを答える

* **物体検出（Object Detection）**：

  * 「どこに・何があるか」を**四角（Bounding Box）**で示す

* **セグメンテーション（Segmentation）**：

  * 「どのピクセルがどのクラス・個体か」まで分かる

G検定では、
**「どこまで分かっていればそのタスクなのか」**が問われる。

---

## 定義・仕組み

### 画像認識タスクの体系（テキスト図）

```
画像認識
├─ 画像分類
│   └─ クラスのみ（位置なし）
│
├─ 物体検出（Object Detection）
│   ├─ Bounding Box（四角）
│   │   ├─ Faster R-CNN
│   │   ├─ YOLO
│   │   └─ SSD
│   └─ 形状拡張
│       └─ Ellipse R-CNN（楕円）
│
└─ セグメンテーション（Segmentation）
    ├─ セマンティックセグメンテーション
    │   └─ クラスごとに領域分割（個体区別なし）
    └─ インスタンスセグメンテーション
        └─ 個体ごとに領域分割（Mask R-CNN）
```

ポイント：

* **下に行くほど出力情報が細かくなる**
* 物体検出 → セグメンテーションの順で理解すると混乱しにくい

---

## いつ使う？（得意・不得意）

### 物体検出

* **得意**：

  * 位置とクラスが分かれば十分なタスク
  * 高速処理が必要（YOLO など）
* **不得意**：

  * 正確な形状・境界が必要な場合

### セマンティックセグメンテーション

* **得意**：

  * 道路・空・背景など「領域」単位の理解
* **不得意**：

  * 同じクラスの個体を区別できない

### インスタンスセグメンテーション

* **得意**：

  * 人・物を**個体ごとに切り分けたい**場合
* **不得意**：

  * 計算量が大きく、処理が重い

---

## G検定ひっかけポイント

### よくある混同①

* ❌ セマンティックセグメンテーションで「人A・人B」を区別できる
* ✅ **区別できるのはインスタンスセグメンテーションのみ**

### よくある混同②

* ❌ Mask R-CNN＝物体検出モデル
* ✅ **物体検出＋インスタンスセグメンテーション**

### 選択肢の即断ルール

* 「**四角で囲む**」 → 物体検出
* 「**ピクセル単位**」 → セグメンテーション
* 「**同じクラスを個体ごとに分ける**」 → インスタンスセグメンテーション
* 「**楕円・回転物体にフィット**」 → Ellipse R-CNN

---

## まとめ（試験直前用）

* 物体検出＝**位置（Bounding Box）**
* セマンティック＝**クラス単位の領域分割**
* インスタンス＝**個体ごとの領域分割**
* Mask R-CNN は最も情報量が多い
* 出力の粒度で一瞬で切り分ける
