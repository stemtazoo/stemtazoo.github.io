---
layout: page
title: BPTT（時間方向の誤差逆伝播）とは？G検定対策
permalink: /gk/bptt/
tags: [gk, rnn, neural_network]
---

## まず結論

* **BPTT（Backpropagation Through Time）**とは、RNNの学習で使われる「**時間方向に展開して誤差逆伝播を行う学習手法**」です。
* G検定では「**RNNの学習方法は何か**」「**LSTMやELMoとどう違うか**」がよく問われます。

## 直感的な説明

* RNNは「過去の状態を引き継ぎながら」処理します。
* BPTTは、RNNを**時間方向にズラッと並べて1本の深いネットワークとして考え、後ろからまとめて反省会（誤差逆伝播）をする**イメージです。
* 普通の誤差逆伝播（Backpropagation）を「**時間軸にも適用したもの**」だと考えると理解しやすいです。

## 定義・仕組み

* BPTTは、RNNを**時系列方向に展開（unroll）**し、
  出力誤差を**未来 → 過去へ**さかのぼって伝播させ、重みを更新します。
* RNNは各時刻で同じ重みを使うため、
  **時間をまたいだ依存関係を考慮して学習できる**のが特徴です。
* 数式は通常の誤差逆伝播と同じ考え方で、
  「**時間方向にも適用する**」点だけが異なります。

## いつ使う？（得意・不得意）

### 得意な場面

* 時系列データ（文章・音声・センサーデータなど）
* RNN / LSTM / GRU などの学習

### 注意が必要な点

* 長い系列では **勾配消失・勾配爆発** が起きやすい
* 計算コストが高くなりやすい
* 実務では **Truncated BPTT（途中で打ち切るBPTT）** がよく使われます

## G検定ひっかけポイント

* **BPTTはモデルではなく「学習手法」**

  * LSTMやGRUと混同しやすいので注意
* 選択肢で

  * 「長期依存を学習するネットワーク」→ ❌（LSTM）
  * 「文脈を考慮した単語表現」→ ❌（ELMo）
  * 「RNNの誤差を時間方向に逆伝播」→ ✅（BPTT）
* **G検定では「RNNの学習過程＝BPTT」と結びつけられるかが判断基準**

## まとめ（試験直前用）

* BPTTは **RNNの学習手法**
* 時間方向に展開して誤差逆伝播を行う
* LSTM・ELMoは「モデル／表現」、BPTTは「学習方法」
* 「時間方向に逆伝播」とあればBPTT
* 
