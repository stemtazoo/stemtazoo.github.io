---
layout: page
title: RNN（再帰型ニューラルネットワーク）
permalink: /gk/rnn/
tags: [gk, neural_network, rnn]
gk_section: ディープラーニングの要素技術/リカレントニューラルネットワーク (RNN)
gk_order: 1
---

## まず結論

* **RNNは時系列データを扱うためのニューラルネットワーク**
* **過去の情報を内部状態として保持** しながら処理する
* 長い系列では **勾配消失・勾配爆発** が起きやすい

---

## 直感的な説明

RNNは、

> 「前の結果を覚えながら、次を判断する仕組み」

です。

* 文章を前から順に読む
* 音声を時間順に聞く
* センサ値の変化を見る

といった、
**順序が意味を持つデータ** に向いています。

---

## 定義・仕組み

### 基本構造

RNNでは、同じネットワークを
**時刻ごとに繰り返し使う** のが特徴です。

* 入力：(x_t)
* 隠れ状態：(h_t)
* 出力：(y_t)

[
h_t = f(Wx_t + Uh_{t-1} + b)
]

---

### 内部状態（隠れ状態）

* 過去の情報を要約したもの
* 次の時刻の計算に引き継がれる

これにより、
**時間的な依存関係** を表現できます。

---

## いつ使う？（得意・不得意）

### 得意なこと

* 時系列データ解析
* 自然言語処理（文章・単語列）
* 音声認識

### 苦手なこと

* 長期依存関係の学習
* 並列計算がしにくい

> これが LSTM / GRU や Transformer につながります。

---

## G検定ひっかけポイント

* ❌「RNNは過去の情報を使わない」→ **誤り**
* ❌「RNNは画像認識に向く」→ **誤り**
* ✅ 内部状態で過去情報を保持
* ✅ 時系列・系列データ向け

---

## まとめ（試験直前用）

* RNNは **時系列向けNN**
* 過去情報を内部状態として保持
* 勾配問題が弱点

👉 次は **勾配消失・勾配爆発** を詳しく見ていきます。
