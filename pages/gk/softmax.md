---
layout: page
title: ソフトマックス関数（Softmax）とは？G検定対策
permalink: /gk/softmax/
tags: [gk, neural_network]
gk_section: 機械学習の概要/代表的な手法/教師あり学習
gk_order: 11
---

## まず結論

* **ソフトマックス関数（Softmax）**とは、ニューラルネットワークの出力を**確率分布（合計が1）に変換する関数**。
* G検定では**数値安定性（オーバーフロー）や確率として扱える条件**がよく問われる。

## 直感的な説明

* 複数の候補（犬・猫・鳥など）に対して、「どれっぽいか」を**割合で出したい**ときに使います。
* 単なるスコアを、

  * 0〜1の範囲に収め
  * 合計が1になるように調整
* つまり、👉 **“一番っぽさ”を確率として表す仕組み**です。

## 定義・仕組み

* ソフトマックス関数は、各クラスの出力スコアに指数関数を適用し、
  その合計で割ることで確率に変換します。

* 特徴：

  * 出力は **0〜1** の範囲
  * **全クラスの合計は1**
  * 多クラス分類で使われる

* 注意点：

  * 指数関数を使うため、**入力が大きいと数値が不安定**になる
  * 実装では最大値を引くなどの工夫が必要

## いつ使う？（得意・不得意）

### 使われる場面（得意）

* 多クラス分類の最終層
* 出力を確率として解釈したい場合

### 注意点・不得意

* 2クラス分類ではシグモイドが使われることも多い
* 数値オーバーフローの対策が必要

## G検定ひっかけポイント

* 正しい説明：

  * ✅ 出力の合計は1
  * ✅ 0〜1の値をとる
  * ❌ 入力が大きくてもオーバーフローしない → **誤り**

* よくある混同：

  * シグモイド関数（2クラス用）
  * 正規化手法（前処理）

* 判断基準：

  * **「確率」「合計1」→ ソフトマックス**
  * **「数値安定性に注意」→ ソフトマックス**

## まとめ（試験直前用）

* ソフトマックス＝確率分布を作る関数
* 出力は0〜1、合計は1
* 多クラス分類で使用
* 指数関数のためオーバーフローに注意
* 「安全」と書かれていたら疑う
