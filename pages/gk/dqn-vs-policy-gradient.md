---
layout: page
title: DQNとPolicy Gradientの違い【強化学習体系図・G検定対策】
permalink: /gk/dqn-vs-policy-gradient/
tags: [gk]
gk_section: ディープラーニングの応用例/深層強化学習
gk_order: 9
---

## まず結論

* **DQN** は「価値（Q値）を学習して行動を選ぶ」手法
* **Policy Gradient** は「行動方針（方策）そのものを直接学習する」手法
* G検定では「**Q値か？方策か？**」で即切り分ける

---

## 直感的な説明

強化学習の考え方は大きく2つある。

* **DQN系**：

  * 「この行動はどれくらい得か？」を全部計算して
  * 一番よさそうな行動を選ぶ

* **Policy Gradient系**：

  * 「この状況では、この行動を取りやすくしよう」と
  * 行動の出やすさ（確率）を直接調整する

イメージ：

* DQN：点数表（Q値）を見て決める
* Policy Gradient：クセ・傾向（方策）を育てる

---

## 定義・仕組み

### DQN（Deep Q-Network）

* ベース：**Q学習（価値ベース手法）**
* 学習対象：

  * Q値（状態 × 行動）
* 特徴：

  * Experience Replay
  * Target Network
* 行動選択：

  * Q値が最大の行動

---

### Policy Gradient

* ベース：**方策勾配法（ポリシー勾配法）**
* 学習対象：

  * 方策（Policy）そのもの
* 特徴：

  * 行動を確率的に選択
  * 勾配で方策を更新
* 行動選択：

  * 方策が出す確率に従う

---

## いつ使う？（得意・不得意）

### DQN

* **得意**：

  * 行動が離散的
  * ゲームAI（Atariなど）
* **不得意**：

  * 連続行動空間

### Policy Gradient

* **得意**：

  * 連続行動空間
  * ロボット制御
* **不得意**：

  * 分散が大きく学習が不安定になりやすい

---

## G検定ひっかけポイント

### ひっかけ①：強化学習＝DQN

* ❌ 強化学習はDQNだけ
* ✅ **DQNは価値ベースの一種**

---

### ひっかけ②：経験再生は必須？

* ❌ 強化学習なら必ず経験再生
* ✅ **経験再生はDQN系の特徴**

---

### 選択肢の判断基準

* 「**Q値を学習**」→ DQN
* 「**経験再生（Experience Replay）**」→ DQN
* 「**方策を直接学習**」→ Policy Gradient
* 「**行動を確率的に選択**」→ Policy Gradient

---

## まとめ（試験直前用）

* DQN＝**価値ベース（Q値）**
* Policy Gradient＝**方策ベース**
* 離散行動→DQN
* 連続行動→Policy Gradient
* 迷ったら「QかPolicyか」で切る
