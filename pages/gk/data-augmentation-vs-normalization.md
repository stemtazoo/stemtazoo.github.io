---
layout: page
title: データ拡張と正規化（BatchNormなど）の違いとは？【G検定頻出整理】
permalink: /gk/data-augmentation-vs-normalization/
tags: [gk, cnn, neural_network]
gk_section: ディープラーニングの応用例/画像認識/データ拡張
gk_order: 6
---

## まず結論
- **データ拡張は「入力データを増やす工夫」**、  
  **正規化（Batch Normalizationなど）は「学習を安定させる工夫」**であり、目的も役割も全く異なる。
- G検定では「**いつ・何に作用するか**」で切り分ける。

## 直感的な説明
この2つは、やっている場所が違います。

- **データ拡張**  
  👉 学習前にデータを増やす
- **正規化**  
  👉 学習中にネットワーク内部を整える

たとえると、
- データ拡張＝**問題集を増やす**
- 正規化＝**勉強しやすい机と椅子を用意する**

という違いです。

## 定義・仕組み
### データ拡張（Data Augmentation）
- 学習データに変換を加えて **データ数・多様性を増やす手法**
- 主に画像データで使用

例：
- 回転
- 反転
- 色変換
- RandAugment / AutoAugment など

目的：
- 過学習の抑制
- 汎化性能の向上

重要：
- **データそのものを変える**
- 学習前の処理

### 正規化（Normalization）
- ネットワーク内部の値を整える手法
- 代表例：**Batch Normalization**

BatchNormの役割：
- 各層の出力分布を安定化
- 勾配消失・爆発の抑制
- 学習の高速化

重要：
- **データは増えない**
- 学習中に作用する

## いつ使う？（得意・不得意）
### データ拡張が効く場面
- 学習データが少ない
- 過学習が起きやすい
- 画像認識タスク

### 正規化が効く場面
- 深いニューラルネットワーク
- 学習が不安定
- 勾配消失・爆発が問題

## G検定ひっかけポイント
ここが超重要です。

### よくある誤解
- ❌「正規化はデータを増やす」
- ❌「データ拡張は学習を安定させる」
- ❌「どちらも前処理だから同じ」

### 正しい判断基準
- **データ数を増やす → データ拡張**
- **分布を安定させる → 正規化**
- **過学習対策 → データ拡張**
- **勾配対策 → 正規化**

問題文に  
「回転・反転・色変換」  
とあれば **データ拡張**。

「Batch Normalization」「分布を安定化」  
とあれば **正規化**。

## 最終比較表（これだけ見ればOK）
| 観点 | データ拡張 | 正規化 |
|---|---|---|
| 作用する場所 | 入力データ | ネットワーク内部 |
| タイミング | 学習前 | 学習中 |
| データ数 | 増える | 増えない |
| 主目的 | 汎化性能向上 | 学習安定化 |
| 代表例 | RandAugment | BatchNorm |

## まとめ（試験直前用）
- データ拡張：データを増やす
- 正規化：学習を安定させる
- 役割は完全に別
- 「いつ・どこで」を見る
- 混同したら負け
