---
layout: page
title: データリーケージ（Data Leakage）とは？【原因と典型例｜G検定対策】
permalink: /gk/data-leakage/
tags: [gk, machine_learning, evaluation]
gk_section: AIの社会実装に向けて/AIの社会実装に向けて
gk_order: 11
---

## まず結論
- **データリーケージ（Data Leakage）**とは、本来予測時には使えない未来情報や答えに近い情報が、学習や特徴量に混入してしまう問題である。
- G検定では「**未来の情報が入っていないか**」を見抜けるかが問われる。

## 直感的な説明
データリーケージは、  
**カンニングしながらテストを受けている状態**です。

- 学習時はものすごく成績が良い  
- でも本番データでは急に当たらなくなる  

👉 理由は、**答えをこっそり見て学習してしまっているから**。

## 定義・仕組み
- 本来、モデルが予測時に知り得ない情報が
- 学習データや特徴量に含まれてしまうこと

### 代表的な例
- 予測対象の未来データが含まれている
- ラベル情報を加工した特徴量を使っている
- 全データで正規化・前処理してから分割している

👉 **評価が不正に良く見える**のが特徴。

## いつ使う？（得意・不得意）
### 発生しやすい場面
- 時系列データ
- 前処理を分割前に実施
- 特徴量エンジニアリングのミス

### 起きないこと
- 学習が停止する
- 処理エラーが出る

👉 **静かに精度を壊す**のがデータリーケージ。

## G検定ひっかけポイント
今回の問題の核心👇

### ⭕ 正しい説明
- **予測時点より未来のデータが含まれている**
- これがデータリーケージの本質

### ❌ よくある誤解
- 学習中に処理が停止する → ❌
- 推論時の精度が高くなる → ❌  
  （むしろ本番では下がる）
- 訓練データ全体に重みを更新 → ❌（バッチ学習）

### 判断基準（試験用）
- 「未来」「答えに近い情報」  
  → **データリーケージ**

## まとめ（試験直前用）
- データリーケージ＝未来情報の混入
- 学習精度は不自然に高くなる
- 本番（検証・推論）で性能低下
- 時系列データで特に注意
- 「未来が見えている」＝即リーケージ
