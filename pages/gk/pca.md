---
layout: page
title: 主成分分析（PCA：Principal Component Analysis）とは？G検定対策
permalink: /gk/pca/
tags: [gk, unsupervised_learning]
gk_section: 機械学習の概要/代表的な手法/教師なし学習
gk_order: 16
---

## まず結論

* **主成分分析（PCA）**とは、ラベルを使わずに**データの分散が最大となる方向（主成分）**を見つけ、次元削減を行う**教師なし学習手法**。
* G検定では**「教師ありではない」「分散最大化」「主成分は直交」**を正しく判断できるかが問われる。

## 直感的な説明

* たくさん点が散らばっているデータを、

  * いちばん広がっている向きに眺めると
  * 少ない軸でも特徴がよく分かります。
* PCAは、
  👉 **データを一番“情報が多く見える向き”に回転させて、軸を減らす方法**です。

## 定義・仕組み

* PCAは、

  * データの分散が最大になる方向を第1主成分とし
  * それと直交しつつ次に分散が大きい方向を第2主成分
  * …と順に主成分を求めます。

* 特徴：

  * 教師なし学習
  * 線形次元削減
  * 主成分同士は**互いに直交（無相関）**

## いつ使う？（得意・不得意）

### 使われる場面（得意）

* 前処理としての次元削減
* 可視化（2次元・3次元）
* ノイズ除去

### 注意点・不得意

* ラベル情報は使えない
* 非線形構造は表現できない

## G検定ひっかけポイント

* よくある誤り表現：

  * ❌ 「教師あり学習である」
  * ❌ 「ラベル情報に基づいて軸を決める」

* 正しい理解：

  * **分散最大化**
  * **教師なし学習**

* 判断基準：

  * 「分散が最大」→ PCA
  * 「ラベルを使う」→ LDA（別物）

## まとめ（試験直前用）

* PCA＝教師なし次元削減
* 分散が最大の方向を探す
* 主成分は直交・無相関
* 前処理・可視化でよく使う
* ラベルは使わない
