---
layout: page
title: LAWS（自律型致死兵器システム）とは？G検定対策
permalink: /gk/laws/
tags: [gk, ethics]
gk_section: AIの法律と倫理/AIの法律と倫理
gk_order: 22
---

## まず結論

* **LAWS（Lethal Autonomous Weapons System）**とは、**人間の直接的な関与なしに、攻撃目標の選択から攻撃までを自律的に行う致死兵器システム**です。
* G検定では、**AI倫理・軍事利用に関する代表的な用語**として出題されます。

## 直感的な説明

* 通常の兵器は、

  * 人間が判断し
  * 人間が発射・攻撃します。

* LAWSは、

  * センサーで状況を認識し
  * AIが判断し
  * **人間の操作なしに攻撃を実行**します。

👉 「**判断と攻撃をAIに任せてしまう兵器**」というイメージです。

## 定義・仕組み

* LAWSは以下の特徴を持ちます。

  * 完全または高度な自律性
  * 人間が最終判断に関与しない
  * 致死的な攻撃能力を持つ

* そのため、

  * 誤認識による誤攻撃
  * 責任の所在が不明確
  * 国際人道法との整合性
    などが問題になります。

## いつ使う？（得意・不得意）

### 話題になる文脈

* AI倫理・社会的影響
* 軍事AI・安全保障
* 国際ルール・規制議論

### 問題点

* 判断の透明性がない
* 説明責任を人間が負えない
* 暴走リスクがある

## G検定ひっかけポイント

* ❌ **「前提条件・行動・結果」で記述される手法**

  * → STRIPS（計画問題）

* ❌ **ディープニューラルネットワークで学習が進まなくなる問題**

  * → 勾配消失問題

* ❌ **複数モデルを組み合わせる手法**

  * → アンサンブル学習

* ⭕ **人間の関与なしに自律的に攻撃を行う致死兵器**

  * → LAWS

👉 **「自律的に攻撃」＋「致死兵器」**が同時に出たらLAWS。

## まとめ（試験直前用）

* LAWS＝自律型致死兵器システム
* 人間の直接操作なしに判断・攻撃
* AI倫理・軍事利用の代表例
* STRIPSや勾配消失とは無関係
* G検定では定義を正確に切れるかが重要
